{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "s1avf0Y2pGAW"
      },
      "source": [
        "####  Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "OxvNJBnSEB33"
      },
      "outputs": [],
      "source": [
        "#@title  { form-width: \"2%\" }\n",
        "#@markdown\n",
        "\n",
        "import sys, os, time, re\n",
        "from datetime import date, datetime\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "import pytz\n",
        "tz = pytz.timezone('Turkey')\n",
        "os.environ['TZ'] = 'Turkey'\n",
        "\n",
        "Env_Colab = False \n",
        "\n",
        "def append_lines(filename,  line = '', lines = None):\n",
        "    if lines or line:\n",
        "        with open(filename, \"a+\") as file:\n",
        "            file.seek(0)\n",
        "            data = file.read(100)\n",
        "            if len(data) > 0:\n",
        "                file.write(\"\\n\")\n",
        "\n",
        "            if line:\n",
        "                file.write(line + \"\\n\")\n",
        "\n",
        "            if lines:\n",
        "                for i in range(len(lines)):\n",
        "                    file.write(lines[i])\n",
        "                    if i < len(lines) - 1:\n",
        "                        file.write(\"\\n\")\n",
        "        return True\n",
        "    return False \n",
        "  \n",
        "log_info = \"Info\"\n",
        "log_warning = \"Warning\"\n",
        "log_error = \"Error\"\n",
        "main = \"Main\"\n",
        "\n",
        "if Env_Colab:\n",
        "    time.tzset()\n",
        "    app_base = '/content/td_logs'\n",
        "    log_file = \"/content/td_logs/td_log.txt\"\n",
        "    log_drv = '/content/drive/MyDrive/General/td_logs'\n",
        "else:\n",
        "    app_base = 'c://td/logs'\n",
        "    log_file = 'c://td/logs/td_log.txt'\n",
        "    log_drv = ''\n",
        "\n",
        "os.makedirs(app_base, exist_ok = True)\n",
        "\n",
        "class Logger:\n",
        "    _instance = None\n",
        "    @staticmethod\n",
        "    def getInstance():\n",
        "        if Logger._instance == None:\n",
        "            Logger()\n",
        "        return Logger._instance\n",
        "  \n",
        "    def __init__(self):\n",
        "        if Logger._instance != None:\n",
        "            raise Exception(\"Logger is a singleton.\")\n",
        "        else:\n",
        "            Logger._instance = self\n",
        "    \n",
        "    logs = []\n",
        "    def init(self, hold = False):\n",
        "        if hold:\n",
        "            self.logs.append(self.makelog('Log started.', log_info, main))\n",
        "        else:\n",
        "            self.log( 'Log started.', log_info,  main)\n",
        "  \n",
        "    def makelog(self, text: str, log_type: str = 'Info', source = main) -> str:\n",
        "        now = datetime.now(tz).strftime(\"%y:%m:%d:%H:%M:%S\")\n",
        "        source = source.replace('_', ' ').title()\n",
        "        start = \"{} {:^7} {}:\". format(now, log_type, source)\n",
        "        text = text.replace(\"\\n\", f\"\\n{start} \")\n",
        "        lg = f\"{start} {text}\"\n",
        "        return lg\n",
        "    \n",
        "    def queue(self, text: str, log_type: str = 'Info', source = main):\n",
        "        self.logs.append(self.makelog(text, log_type = log_type, source = source))\n",
        "  \n",
        "    def info(self, text: str = \"\", lines = None):\n",
        "        src = sys._getframe(1).f_code.co_name\n",
        "        if src == '<module>':\n",
        "            src = main\n",
        "\n",
        "        if lines:\n",
        "            for line in lines:\n",
        "                self.queue(line, log_info, src)\n",
        "        if text:\n",
        "            self.queue(text, log_info, src)\n",
        "  \n",
        "    def warning(self, text: str = \"\", lines = None):\n",
        "        src = sys._getframe(1).f_code.co_name\n",
        "        if src == '<module>':\n",
        "            src = main\n",
        "\n",
        "        if lines:\n",
        "            for line in lines:\n",
        "                self.queue(line, log_warning, src)\n",
        "        if text:\n",
        "            self.queue(text, log_warning, src)  \n",
        "  \n",
        "    def error(self, text: str = \"\", lines = None):\n",
        "        src = sys._getframe(1).f_code.co_name\n",
        "        if src == '<module>':\n",
        "            src = main\n",
        "\n",
        "        if lines:\n",
        "            for line in lines:\n",
        "                self.queue(line, log_error, src)\n",
        "        if text:\n",
        "            self.queue(text, log_error, src)\n",
        "    \n",
        "    def release(self):\n",
        "        if (self.logs):\n",
        "            if self.log(logs = self.logs):\n",
        "                self.logs.clear()\n",
        "            else:\n",
        "                print(\"Logger: An error happend while trying to write log. logs are preserved.\")\n",
        "  \n",
        "    def log(self, text = '', log_type= log_info,  source = main, logs = None):\n",
        "        if not logs and not text:\n",
        "            return True\n",
        "        res = False\n",
        "        if text:\n",
        "            text = self.makelog(text, log_type, source)\n",
        "        res = append_lines(filename = log_file, line = text, lines = logs)\n",
        "\n",
        "        if res:\n",
        "            self.savelogtodrive()\n",
        "            return True\n",
        "        else:\n",
        "            print(\"Logger: log: An error happened while trying to write log.\")\n",
        "            return False\n",
        "  \n",
        "    def savelogtodrive(self):\n",
        "        if log_drv and os.path.exists(log_drv) and os.path.isfile(log_file):\n",
        "            if Env_Colab:\n",
        "                !rsync -I \"$log_file\" \"$log_drv_file\"\n",
        "\n",
        "logger = Logger.getInstance()   \n",
        "info = logger.info\n",
        "error = logger.error\n",
        "warning = logger.warning\n",
        "release = logger.release\n",
        "\n",
        "if not os.path.isfile(log_file):\n",
        "    logger.init(True)\n",
        "    info(f\"New Session.\")\n",
        "\n",
        "nowstr = lambda separete = False: datetime.now(tz).strftime(\"%y-%m-%d-%H-%M-%S\") if separete else str(round(time.time()))\n",
        "\n",
        "skip = lambda c: True if c == \"\" or c == \"s\" else False\n",
        "def ext (c):\n",
        "    c = c.lower()\n",
        "    return True if c == \" \" or c == \"q\" else False\n",
        "\n",
        "def no(c):\n",
        "    c = c.lower()\n",
        "    return True if c == \"n\" else False\n",
        "\n",
        "def getattrs(obj):\n",
        "    attrs_ = []\n",
        "    for attr in dir(obj):\n",
        "        if not attr.startswith(\"__\"):\n",
        "            attrs_.append((attr, getattr(obj, attr)))\n",
        "    return attrs_\n",
        "\n",
        "def dump(obj, padding = True, filter = True):\n",
        "    pad = \"              \" if padding else \"\"\n",
        "    for attr in dir(obj):\n",
        "        if filter and attr.startswith(\"__\"):\n",
        "            continue\n",
        "        print(\"%s%s =  %r\" % (pad, attr, getattr(obj, attr)))\n",
        "\n",
        "def getattrstr(obj, filter = True, filter_empty = False, add_line = False):\n",
        "    attrstr = ''\n",
        "    pre = '\\n' if add_line else ', '\n",
        "    i = True\n",
        "    for attr in dir(obj):\n",
        "        if filter and attr.startswith(\"__\"):\n",
        "            continue\n",
        "        val = getattr(obj, attr)\n",
        "        if filter_empty and not val:\n",
        "            continue\n",
        "        if i :\n",
        "            attrstr += \"%s =  %r\" % (attr, val)\n",
        "            i = False\n",
        "        else:\n",
        "            attrstr += \"%s%s =  %r\" % (pre, attr, getattr(obj, attr))\n",
        "    return attrstr\n",
        "  \n",
        "\n",
        "def list_lines(lines, str = False):\n",
        "    if lines:\n",
        "        if str:\n",
        "            rtn = ''\n",
        "            for r in lines:\n",
        "                if r:\n",
        "                    rtn += (r +'\\n')\n",
        "            return rtn\n",
        "        if not str:  \n",
        "            for line in lines:\n",
        "                print(line)\n",
        "\n",
        "size_limit = 40000\n",
        "def pathsize(path, string = False):\n",
        "    size = 0\n",
        "    if not os.path.exists(path):\n",
        "        return 0\n",
        "    if os.path.isfile(path):\n",
        "        size = os.path.getsize(path)\n",
        "    else:  \n",
        "      for path, dirs, files in os.walk(path):\n",
        "          for f in files:\n",
        "              fp = os.path.join(path, f)\n",
        "              size += os.path.getsize(fp)\n",
        "    if string:\n",
        "        return data_str(size)\n",
        "    else:\n",
        "        return size\n",
        "\n",
        "def has_size(path, only_check = True):\n",
        "    size = 0\n",
        "    if not os.path.exists(path):\n",
        "        return 0\n",
        "    if os.path.isfile(path):\n",
        "        size = os.path.getsize(path)\n",
        "    else:  \n",
        "        for path, dirs, files in os.walk(path):\n",
        "            for f in files:\n",
        "                fp = os.path.join(path, f)\n",
        "                size += os.path.getsize(fp)\n",
        "                if only_check and size >= size_limit:\n",
        "                    return size\n",
        "    if size >= size_limit:\n",
        "        return size\n",
        "    else:\n",
        "        return 0\n",
        "  \n",
        "def is_hidden(path):\n",
        "    return True if path[0] == '.' else False\n",
        "\n",
        "def filter_checks(dirs):\n",
        "    for dir in dirs:\n",
        "        if dir.endswith('ipynb_checkpoints'):\n",
        "            dirs.remove(dir)\n",
        "    return dirs\n",
        "\n",
        "def print_files(drs, range_start , range_end):\n",
        "    for i in range(range_start, range_end):\n",
        "        print(\"   {0}-  {1}\".format(i+1, drs[i])) \n",
        "\n",
        "def data_str(byte_val):\n",
        "    size = ByteToGB(byte_val)\n",
        "    if (size >= 1):\n",
        "        return \"{:.1f} GB\".format(size)\n",
        "    size = ByteToMB(byte_val)\n",
        "    if (size >= 1):\n",
        "        return \"{:.1f} MB\".format(size)\n",
        "    size = ByteToKB(byte_val)\n",
        "    if (size >= 1):\n",
        "        return \"{:.1f} KB\".format(size)\n",
        "    return \"{:.1f} B\".format(size)\n",
        "\n",
        "def speed_str(byte_val):\n",
        "    size_mb = ByteToMB(byte_val)\n",
        "    if (size_mb >= 1):\n",
        "        return \"{:.1f} MB\".format(size_mb)\n",
        "    else:\n",
        "        return \"{:.1f} KB\".format(ByteToKB(byte_val))\n",
        "    \n",
        "def RoundTo1(n) :\n",
        "    if n < 1 and (n - 0.9765625) >= 0 :\n",
        "        return 1\n",
        "    else: \n",
        "        return n\n",
        "\n",
        "ByteToGB = lambda n: RoundTo1(n / 1073741824)\n",
        "ByteToMB = lambda n: RoundTo1(n/ 1048576)\n",
        "ByteToKB = lambda n: RoundTo1(n/ 1024)\n",
        "contains = lambda string, search: search.lower() in string.lower()\n",
        "time_str = lambda sec: time.strftime('%H:%M:%S', time.gmtime(sec))\n",
        "\n",
        "checkpoint = '.ipynb_checkpoints'\n",
        "savetodrive = 'Save to Google Drive'\n",
        "savetoftp = 'Save to FTP'\n",
        "enableftpstate = False\n",
        "enablegdrivestate = False\n",
        "\n",
        "class SystemConfig():\n",
        "    _instance = None\n",
        "    @staticmethod\n",
        "    def instance():\n",
        "        if SystemConfig._instance == None:\n",
        "            SystemConfig()\n",
        "        return SystemConfig._instance\n",
        "    def __init__(self):\n",
        "        if SystemConfig._instance != None:\n",
        "            raise Exception(\"Logger is a singleton.\")            \n",
        "        else:\n",
        "            SystemConfig._instance = self\n",
        "\n",
        "    filemanagerenabled = False\n",
        "    xmltoolsenabled = False\n",
        "    mysqltoolsenabled = False\n",
        "    csvtoolsenabled = False\n",
        "\n",
        "    gdriveenabled = False\n",
        "    ftpenabled = False\n",
        "\n",
        "    ftpuser = \"\"\n",
        "    ftppassword = \"\"\n",
        "    ftphost = \"\"\n",
        "\n",
        "config = SystemConfig.instance()\n",
        "\n",
        "### general style\n",
        "layout_15 ={'width':'auto', 'flex':'15 1 0%', 'align_items':\"center\"}\n",
        "layout_10 ={'width':'auto', 'flex':'10 1 0%', 'align_items':\"center\"}\n",
        "layout_8 ={'width':'auto', 'flex':'8 1 0%', 'align_items':\"center\"}\n",
        "layout_7 ={'width':'auto', 'flex':'7 1 0%', 'align_items':\"center\"}\n",
        "layout_5 ={'width':'auto', 'flex':'5 1 0%', 'align_items':\"center\"}\n",
        "layout_4 ={'width':'auto', 'flex':'4 1 0%', 'align_items':\"center\"}\n",
        "layout_3 ={'width':'auto', 'flex':'3 1 0%', 'align_items':\"center\"}\n",
        "layout_2 ={'width':'auto', 'flex':'2 1 0%', 'align_items':\"center\"}\n",
        "layout_1 ={'width':'auto', 'flex':'1 1 0%', 'align_items':\"center\"}\n",
        "layout_1E ={'width':'auto', 'flex':'1 1 0%', 'align_items':\"flex-start\"}\n",
        "\n",
        "col4layout = {'width':'%25','flex':'3 1 0%', 'align_items':\"center\"}\n",
        "col3layout = {'width':'%33','flex':'2 1 0%', 'align_items':\"center\"}\n",
        "col2layout = {'width':'%50','flex':'1 1 0%', 'align_items':\"center\"}\n",
        "\n",
        "empty_label_1 = widgets.Label(value = \"\", layout = layout_1)\n",
        "empty_label_2 = widgets.Label(value = \"\", layout = layout_2)\n",
        "empty_label_3 = widgets.Label(value = \"\", layout = layout_3)\n",
        "empty_label_4 = widgets.Label(value = \"\", layout = layout_4)\n",
        "empty_label_5 = widgets.Label(value = \"\", layout = layout_5)\n",
        "\n",
        "whitespace1 = ' '\n",
        "whitespace2 = '  '\n",
        "whitespace3 = '   '\n",
        "whitespace4 = '    '\n",
        "whitespace5 = '     '\n",
        "\n",
        "### custom style\n",
        "rowlayout = {\n",
        "    'flex_flow':'row',\n",
        "    'align_items':'center',\n",
        "    'width':'80%',\n",
        "    'height':'160px',\n",
        "    'justify_content':'center'}\n",
        "\n",
        "saverowlayout = {\n",
        "    'flex_flow':'row',\n",
        "    'align_items':'center',\n",
        "    'width':'80%',\n",
        "    'justify_content':'center'\n",
        "    }\n",
        "\n",
        "input_style = {\"description_width\":\"120px\"}\n",
        "samplestyle = {\"padding-left\":\"200px\",\"padding-right\":\"200px\"}\n",
        "conflabelstyle = {\"padding-left\":\"150px\"}\n",
        "\n",
        "\n",
        "def saveconffilehandler(button):\n",
        "    saveconfoutputlabel.value = \"Configuration saved to file.\"\n",
        "\n",
        "def loadconffilehandler(button):\n",
        "    saveconfoutputlabel.value = \"Configuration loaded.\"\n",
        "\n",
        "def saveconfhandler(button):\n",
        "    config.gdriveenabled = gdrivetogglecheckbox.value\n",
        "    config.ftpenabled = ftptogglecheckbox.value\n",
        "    if config.ftpenabled:\n",
        "        config.ftphost = ftphosttext.value.strip()\n",
        "        config.ftpuser = ftpusertext.value.strip()\n",
        "        config.ftppassword = ftppasstext.value.strip()\n",
        "    config.filemanagerenabled = filemanagertogglecheckbox.value\n",
        "    config.csvtoolsenabled = csvtogglecheckbox.value\n",
        "    config.xmltoolsenabled = xmltogglecheckbox.value\n",
        "    config.mysqltoolsenabled = mysqltogglecheckbox.value\n",
        "    if validateconfig():\n",
        "        enabletools()\n",
        "        saveconfoutputlabel.value = \"Configuration saved.\"\n",
        "    else:\n",
        "        saveconfoutputlabel.value = \"Validation failed.\"\n",
        "\n",
        "def validateconfig():\n",
        "    if config.ftpenabled:\n",
        "        if not (config.ftphost and config.ftpuser and config.ftppassword):\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "##### row1\n",
        "### r1v1\n",
        "ftptogglecheckbox = widgets.Checkbox(\n",
        "    description= \"Enable FTP\",\n",
        "    value= False,\n",
        "    disabled= False\n",
        ")\n",
        "gdrivetogglecheckbox = widgets.Checkbox(\n",
        "    description= \"Enable Google Dirve\"\n",
        ")\n",
        "storagetogglesvbox = widgets.VBox(\n",
        " [ftptogglecheckbox, gdrivetogglecheckbox],\n",
        "    layout= col4layout\n",
        ")\n",
        "\n",
        "### r1v2\n",
        "ftphosttext = widgets.Text(\n",
        "    placeholder= \"FTP host address\",\n",
        "    description= \"FTP Host\",\n",
        "    style= input_style\n",
        "    )\n",
        "ftpusertext = widgets.Text(\n",
        "    placeholder= \"FTP account username\",\n",
        "    description= \"FTP Username\",\n",
        "    style= input_style\n",
        "    )\n",
        "ftppasstext = widgets.Password(\n",
        "    placeholder= \"FTP account Password\",\n",
        "    description=\"FTP Password\",\n",
        "    style= input_style\n",
        ")\n",
        "ftpvbox = widgets.VBox(\n",
        "    [ftphosttext, ftpusertext, ftppasstext],\n",
        "    layout= col4layout\n",
        "    )\n",
        "\n",
        "### r1v3\n",
        "r1v3vbox = widgets.VBox(\n",
        " [ ],\n",
        "    layout= col4layout\n",
        ")\n",
        "### r1v4\n",
        "\n",
        "###\n",
        "row1hbox = widgets.HBox(\n",
        "     [\n",
        "      storagetogglesvbox,\n",
        "      ftpvbox,\n",
        "      r1v3vbox\n",
        "      ],\n",
        "    layout= rowlayout\n",
        ")\n",
        "##### row 2\n",
        "### r2v1\n",
        "filemanagertogglecheckbox = widgets.Checkbox(\n",
        "    description= \"Enable File Manager\",\n",
        "    value= False\n",
        ")\n",
        "\n",
        "csvtogglecheckbox = widgets.Checkbox(\n",
        "    description= \"Enable CSV Tools\",\n",
        "    value= False\n",
        ")\n",
        "\n",
        "toggles1vbox = widgets.VBox(\n",
        " [ filemanagertogglecheckbox, csvtogglecheckbox],\n",
        "    layout= col4layout\n",
        ")\n",
        "\n",
        "### r2v2\n",
        "xmltogglecheckbox = widgets.Checkbox(\n",
        "    description= \"Enable XML Tools\",\n",
        "    value= False\n",
        ")\n",
        "\n",
        "mysqltogglecheckbox = widgets.Checkbox(\n",
        "    description= \"Enable MySQL Tools\",\n",
        "    value= False\n",
        ")\n",
        "\n",
        "toggles2vbox = widgets.VBox(\n",
        " [ xmltogglecheckbox, mysqltogglecheckbox],\n",
        "    layout= col4layout\n",
        ")\n",
        "### r2v3\n",
        "r2v3vbox = widgets.VBox(\n",
        " [ ],\n",
        "    layout= col4layout\n",
        ")\n",
        "###\n",
        "row2hbox = widgets.HBox(\n",
        "    [toggles1vbox, toggles2vbox, r2v3vbox],\n",
        "    layout= rowlayout\n",
        ")\n",
        "##### row 3\n",
        "### r3v1\n",
        "conffiletext = widgets.Text(\n",
        "    placeholder= \"Configuration File\",\n",
        "    description= \"Configuration File\",\n",
        "    value= '',\n",
        "    style= input_style\n",
        "    )\n",
        "\n",
        "saveconffilebutton = widgets.Button(\n",
        "    description= \"Save\",\n",
        ")\n",
        "saveconffilebutton.on_click(saveconffilehandler)\n",
        "\n",
        "loadconffilebutton = widgets.Button(\n",
        "    description= \"Load\",\n",
        ")\n",
        "loadconffilebutton.on_click(loadconffilehandler)\n",
        "\n",
        "conffilehbox = widgets.HBox(\n",
        "    [saveconffilebutton, loadconffilebutton],\n",
        "    layout= {\"width\":\"auto\",\"justify-content\":\"space-around\"}\n",
        ")\n",
        "conffilevbox = widgets.VBox(\n",
        "    [conffiletext, conffilehbox],\n",
        "    layout= col2layout\n",
        "    )\n",
        "\n",
        "### r3v2\n",
        "r3v2vbox = widgets.VBox(\n",
        "    [],\n",
        "    layout= col2layout\n",
        "    )\n",
        "###\n",
        "row3hbox = widgets.HBox(\n",
        "    [conffilevbox, r3v2vbox],\n",
        "    layout= rowlayout\n",
        ")\n",
        "##### row 4\n",
        "saveconfbutton = widgets.Button(\n",
        "    description= \"Save\",\n",
        ")\n",
        "\n",
        "saveconfbutton.on_click(saveconfhandler)\n",
        "\n",
        "saveconfoutputlabel = widgets.Label(\n",
        "    value= \"\",\n",
        "    style= conflabelstyle,\n",
        "    layout= layout_4\n",
        ")\n",
        "saveconfigBox = widgets.Box(\n",
        "    [empty_label_3 ,saveconfbutton, empty_label_1, saveconfoutputlabel],\n",
        "    layout= saverowlayout\n",
        ")\n",
        "row4hbox = widgets.HBox(\n",
        "    [saveconfigBox],\n",
        "    layout= rowlayout\n",
        ")\n",
        "####\n",
        "\n",
        "\n",
        "display(row1hbox, row2hbox, row3hbox, row4hbox)\n",
        "\n",
        "from ast import List\n",
        "import json, requests, codecs\n",
        "\n",
        "get = requests.get\n",
        "head = requests.head\n",
        "\n",
        "if Env_Colab and not 'init' in globals():    \n",
        "    !rm -r \"/content/sample_data\"    \n",
        "    from google.colab import drive\n",
        "    if config.gdriveenabled and not os.path.exists(\"/content/drive\"):\n",
        "        drive.mount('/content/drive')\n",
        "        init = True\n",
        "\n",
        "    if os.path.exists(\"/content/drive\"):\n",
        "        now = datetime.now(tz).strftime(\"%y-%m-%d-%H-%M-%S\")\n",
        "        log_drv = \"\"\n",
        "        if log_drv and os.path.exists(f'/content/drive/Shareddrives/{log_drv}') :\n",
        "            log_drv = f'/content/drive/Shareddrives/{log_drv}/Downloads/td_logs'\n",
        "            log_drv_file =  f'/content/drive/Shareddrives/{log_drv}/Downloads/td_logs/td_log_{now}.txt'\n",
        "            os.makedirs(log_drv, exist_ok= True)\n",
        "        else:\n",
        "            log_drv_file = f'{log_drv}/td_log_{now}.txt'\n",
        "    else:\n",
        "        log_drv = log_drv_file = ''\n",
        "\n",
        "    if os.path.exists('/content/drive'):\n",
        "        os.makedirs(log_drv, exist_ok = True)\n",
        "        info(\"Google drive is mounted.\")\n",
        "\n",
        "    init = True\n",
        "\n",
        "if not os.path.isfile(log_file):\n",
        "    logger.init(True)\n",
        "\n",
        "def enabletools():\n",
        "    if config.ftpenabled and not 'ftputil' in globals():\n",
        "        !pip install ftputil &> /dev/null\n",
        "        !sudo apt-get install lftp &> /dev/null\n",
        "\n",
        "    if config.mysqltoolsenabled and not 'MySQLdb' in globals():\n",
        "        !curl emasri.com &> /dev/null\n",
        "        !pip install mysqlclient &> /dev/null\n",
        "\n",
        "    if config.ftpenabled:\n",
        "        import ftputil\n",
        "\n",
        "ext_re = r\"\\.\\w+$\"\n",
        "extdot_re = r\"\\.(?=\\w+$)\"\n",
        "file_re = r\"^.*\\.[A-Z,a-z,0-9]+$\"\n",
        "sd_re = r\"(\\/content\\/drive\\/Shareddrives\\/)[A-Za-z0-9]+(?=\\/)\"\n",
        "anybk_re = r\"(?<=Shareddrives\\/)([A-Za-z0-9]*(?=[Bb][1-9])|[A-Za-z0-9]*)\"\n",
        "backup_re = r\"(?<=Shareddrives\\/).*(?=\\/)\"\n",
        "url_re = r\"((http[s]?):\\/\\/)?([^:\\/\\s]+)((\\/\\w+\\/)*\\/)([\\w\\-\\.]+[^#?\\s]+)(.*)?(#[\\w\\-]+)?\"\n",
        "file_url_re = r\"((http[s]?):\\/\\/)?([^:\\/\\s\\\"<>(\\\\n)]+)((\\/\\w{3}\\/)*\\/)([\\w\\-\\.]+[^#?\\s\\\"<>(\\\\n)]+)([^:\\/\\s\\\"<>(\\\\n)].*)?(#[\\w\\-]+)?\"\n",
        "\n",
        "exlessbase = lambda path: os.path.basename(os.path.splitext(path)[0])\n",
        "\n",
        "def getbackup(path: str, bakid = \"\", bak_index = 0):\n",
        "    if bakid:\n",
        "        search = re.search(backup_re, path)\n",
        "        if not search:\n",
        "            error(\"Invalid shared drive path.\")\n",
        "            release()\n",
        "            raise \"Invalid shared drive path.\"\n",
        "        return re.sub(backup_re, bakid, path, 1)\n",
        "    elif bak_index:\n",
        "        search = re.search(anybk_re, path)\n",
        "        if not search:\n",
        "            error(\"Invalid shared drive path.\")\n",
        "            release()\n",
        "            raise \"Invalid shared drive path.\"\n",
        "        bakbase = search.group()\n",
        "        replace = bakbase + f\"B{bak_index}\"\n",
        "        bakpath = path.replace(bakbase, replace, 1)\n",
        "        return (replace, bakpath)\n",
        "    else:\n",
        "        error(\"No backup id or index.\")\n",
        "        release()\n",
        "        raise(\"No backup id or index.\")\n",
        "\n",
        "def transstring(name): \n",
        "    if not name:\n",
        "        error('String is empty.')\n",
        "        raise Exception('String is empty.')\n",
        "    table = name.maketrans(\"\",\"\",\" ,.;:!?'&#$%`!@^*_-/\\\\|'\\\"<>())[]{}\")\n",
        "    return name.translate(table).lower()\n",
        "\n",
        "sharedbase = '/content/drive/Shareddrives/'\n",
        "\n",
        "def check_ok(url, v = False):\n",
        "    res = head(url).status_code\n",
        "    if res != 200:\n",
        "        print(f\"  Resource not found {res} {url}\")\n",
        "        return\n",
        "    print(f\"  Ok 200.\")\n",
        "\n",
        "def write_json( dct, filename = 'new_json.json', overwrite = False):\n",
        "    if not dct:\n",
        "        error(\"Empty input\")\n",
        "        raise Exception(\"Empty input\")\n",
        "\n",
        "    text = json.dumps(dct, ensure_ascii = False, indent = 2)\n",
        "    output_file = filename\n",
        "    i = 0\n",
        "    if not overwrite:\n",
        "        while True:\n",
        "            i += 1\n",
        "            if os.path.exists(output_file):\n",
        "                sch = re.search(extdot_re, output_file)\n",
        "                if sch:\n",
        "                    output_file = re.sub(extdot_re, f\"{i}.\", filename)\n",
        "                else:\n",
        "                    output_file = f\"{filename}{i}\"  \n",
        "            else: \n",
        "                break\n",
        "        \n",
        "    with open(output_file, 'w', encoding = 'utf8') as file:\n",
        "        print(f\"Writing JSON file: {output_file}\")\n",
        "        file.write(text)\n",
        "        print(\"-- Done --\")\n",
        "\n",
        "def read_json(filename, encoding = 'utf8'):\n",
        "    with codecs.open(filename, 'r', encoding) as file:\n",
        "        json_ = json.load(file)    \n",
        "        return json_\n",
        "    \n",
        "def createcommalist(valuelist, sep = ',', wrap = False, spaced = True):\n",
        "    if valuelist:\n",
        "        valuestr = \"\"\n",
        "        sep += ' ' if spaced else ''\n",
        "        for value in valuelist:\n",
        "            value = value.strip()\n",
        "            if value:  \n",
        "                valuestr += value.strip() + sep\n",
        "        return f'\"{valuestr[:-len(sep)]}\"' if wrap else valuestr[:-len(sep)]\n",
        "\n",
        "def parsecommalist(commalist, sep = ','):\n",
        "    if commalist:\n",
        "        parsedlist = commalist.split(sep)\n",
        "        i = 0\n",
        "        for value in parsedlist:\n",
        "            parsedlist[i] = value.strip()\n",
        "            i += 1\n",
        "        return parsedlist\n",
        "  \n",
        "################################\n",
        "######## File Manager ##########\n",
        "\n",
        "if config.filemanagerenabled:\n",
        "    def mv(from_path, to_path, content = None, backup = False):\n",
        "        if to_path:\n",
        "            os.makedirs(to_path, exist_ok= True)  \n",
        "            if content:\n",
        "                info(f\"Moving batch of files to: {to_path}\")\n",
        "                print(\"\\n Enter selection to move [item1,item2,start-end  All: . Exit: q]:\\n\")\n",
        "                print_files(content, 0 ,len(content))\n",
        "                print()\n",
        "                items: List[int] = []\n",
        "                start = end = 0\n",
        "                inpt = input()\n",
        "                if ext(inpt):\n",
        "                    return\n",
        "                if '.' == inpt:\n",
        "                    start = 0\n",
        "                    end = len(content)    \n",
        "                    items.extend(range(start, end))\n",
        "                else:\n",
        "                    rngs = inpt.split(',')\n",
        "                    for rng in rngs:\n",
        "                        if '-' in rng:\n",
        "                            rngs = rng.split('-')\n",
        "                            start = int(rngs[0]) - 1\n",
        "                            end = int((rngs[1]))\n",
        "                            items.extend(range(start, end))      \n",
        "                            if end > len(content) or start < 0 :\n",
        "                                print(\"The ranges' ends are out of the directory file range.\")\n",
        "                            continue\n",
        "                        else:\n",
        "                            i = int(rng)-1\n",
        "                            items.append(i)\n",
        "            else:\n",
        "                info(f'Moving: {from_path} to {to_path}\\nProcess backup: {backup}')\n",
        "                print(f'Moving: {from_path} to {to_path}\\nProcess backup: {backup}')\n",
        "                items = [0]\n",
        "\n",
        "            for i in items:        \n",
        "                p1 = from_path + \"/\" +  content[i] if content else from_path\n",
        "                info(f\"Moving {p1} to: {to_path}\")\n",
        "                print(f\"Moving {p1} to: {to_path}\")\n",
        "                os.makedirs(to_path, exist_ok= True)\n",
        "                cmd = f'mv \"{p1}\" \"{to_path}\"'\n",
        "                print(f' {cmd}')\n",
        "                !$cmd\n",
        "                if backup:\n",
        "                    info(f\"Processing backup.\")\n",
        "                    for i in range(1,4):\n",
        "                        p11bak = getbackup(p1, bak_index = i)\n",
        "                        tpbak = getbackup(to_path, bak_index = i)\n",
        "                        if not (p11bak[0]in from_path and tpbak[0] in to_path):\n",
        "                            tp =  tpbak[1]\n",
        "                            p11 = p11bak[1]\n",
        "                            p21 = tp +  rename\n",
        "                            if os.path.exists(p11):\n",
        "                                os.makedirs(tp, exist_ok= True)\n",
        "                                print(f\"Moving {p11} to {p21}\\n\")\n",
        "                                info(f\"Moving {p11} to {p21}\")\n",
        "                                cmd = f'mv \"{p11}\" \"{p21}\"'\n",
        "                                print(f' {cmd}')\n",
        "                                !$cmd\n",
        "                            else:\n",
        "                                print(f\"Backup {p11} Doesn't exist.\\n\")\n",
        "                                warning(f\"Backup {p11} Doesn't exist.\")\n",
        "\n",
        "            print(\"\\n   .....................\\n           Done\\n\")\n",
        "            info(\"Moving done.\")\n",
        "            return            \n",
        "        else:\n",
        "            error(\"No distination provided.\")\n",
        "            return\n",
        "\n",
        "    def cp(from_path, to_path, content = None, backup = False, beforedate = None, afterdate = None, native = False):\n",
        "        if to_path:\n",
        "            os.makedirs(to_path, exist_ok= True)  \n",
        "            if content:\n",
        "                info(f\"Copying batch of files to: {to_path}\")\n",
        "                print(\"\\n Enter selection to copy ['item1, item2..' 'start-end'  All: '.' Exit: 'q']:\\n\")\n",
        "                print_files(content, 0 ,len(content))\n",
        "                print()\n",
        "                items: List[int] = []\n",
        "                start = end = 0\n",
        "                inpt = input().strip()\n",
        "                if ext(inpt):\n",
        "                    return\n",
        "                if '.' == inpt:\n",
        "                    start = 0\n",
        "                    end = len(content)\n",
        "                    items.extend(range(start, end))  \n",
        "                else:\n",
        "                    rngs = inpt.split(',')\n",
        "                    for rng in rngs:\n",
        "                        if '-' in rng:\n",
        "                            rngs = rng.split('-')\n",
        "                            start = int(rngs[0]) - 1\n",
        "                            end = int((rngs[1]))\n",
        "                            items.extend(range(start, end))      \n",
        "                            if end > len(content) or start < 0 :\n",
        "                                print(\"The ranges' ends are out of the directory file range.\")\n",
        "                            continue\n",
        "                        else:\n",
        "                            i = int(rng)-1\n",
        "                            items.append(i)\n",
        "            else:\n",
        "                info(f'Copying: {from_path}\\nProcess backup: {backup}')\n",
        "                items = [0]\n",
        "\n",
        "            for i in items:\n",
        "                newname  = \"\"\n",
        "                p1 = from_path + \"/\" + content[i] if content else from_path\n",
        "                if newname:\n",
        "                    p2 = from_path + \"/\" +  newname if content else os.path.dirname(from_path) + '/' + newname\n",
        "                    print(\"  Renaming:  {} to {}\".format(items[i], newname))\n",
        "                    !mv \"p1\" \"$p2\"\n",
        "                    p1 = p2\n",
        "\n",
        "                tool = \"cp (doesn't support merge)\" if native else \"rsync (supports merge)\"\n",
        "                cmd = f'rsync -r --size-only  \"{p1}\" \"{to_path}\"' if not native else f'cp -r \"{p1}\" \"{to_path}\"'\n",
        "                print(f\"Copying:  {p1} to {to_path} Using {tool}\\n {cmd}\")\n",
        "                info(f\"Copying:  {p1} to {to_path} Using {tool}\\n {cmd}\")\n",
        "                !$cmd\n",
        "\n",
        "                if backup:\n",
        "                    for i in range(1,4):\n",
        "                        p3bak = getbackup(to_path, bak_index = i)\n",
        "                        if not (p3bak[0]in from_path and p3bak[0] in to_path):\n",
        "                            p3 =  p3bak[1]\n",
        "                            os.makedirs(p3, exist_ok= True)\n",
        "                            cmd = f'rsync -r --size-only  \"{p1}\" \"{p3}\"' if not native else f'cp -r \"{p1}\" \"{p3}\"'\n",
        "                            print(f\"Copying  {p1} to {p3}\\n {cmd}\")\n",
        "                            info(f\"Copying:  {p1} to {p3}\\n {cmd}\")\n",
        "                            !$cmd \n",
        "            print('..... Done .....\\n')\n",
        "\n",
        "\n",
        "    def rename(path, newpath, backup, content = None):\n",
        "        print(f\"Renaming:  {path[27:]} to {newpath[27:]}\")\n",
        "        !mv \"$path\" \"$newpath\" \n",
        "        if backup:\n",
        "            for i in range(1,4):\n",
        "                pathbu = getbackup(path, bak_index = i)\n",
        "                newpathbu = getbackup(newpath, bak_index = i)\n",
        "                if not pathbu[0] in path and os.path.exists(pathbu[1]):\n",
        "                    path = pathbu[1]\n",
        "                    newpath = newpathbu[1]    \n",
        "                    print(f\"Renaming:  {path[27:]} to {newpath[27:]}\")\n",
        "                    !mv \"$path\" \"$newpath\"      \n",
        "\n",
        "        print(\"......................\")\n",
        "        print(\"       Done\")\n",
        "        return  \n",
        "    \n",
        "    def rm(delpath, process_backup = False, content = None, v = False):\n",
        "        if content:\n",
        "            content.sort()\n",
        "            info(f'Deleing files in from: {delpath}\\nProcess backup: {process_backup}')\n",
        "            print(\" Enter directory selection to remove: [s-e],2  '.' = All \")\n",
        "            items: List[int] = []\n",
        "            print_files(content, 0 ,len(content))\n",
        "            print()\n",
        "            start = end = 0\n",
        "            inpt = input()\n",
        "            if ext(inpt):\n",
        "                return\n",
        "            if '.' == inpt:\n",
        "                start = 0\n",
        "                end = len(rng)      \n",
        "            else:\n",
        "                rngs = inpt.split(',')\n",
        "                for rng in rngs:\n",
        "                    if '-' in rng:\n",
        "                        rngs = rng.split('-')\n",
        "                        start = int(rngs[0]) - 1\n",
        "                        end = int((rngs[1]))\n",
        "                        items.extend(range(start, end))      \n",
        "                        if end > len(content) or start < 0 :\n",
        "                            print(\"The ranges' ends are out of the directory file range.\")\n",
        "                        continue\n",
        "                    else:\n",
        "                        i = int(rng)-1\n",
        "                        items.append(i)\n",
        "\n",
        "        elif delpath:\n",
        "            info(f'Deleing: {delpath}\\nProcess backup: {process_backup}')\n",
        "            items = [0]\n",
        "        else:\n",
        "            return -1\n",
        "\n",
        "        for i in items:\n",
        "            path = delpath + \"/\" + content[i] if content else delpath\n",
        "            if v:\n",
        "                print(f\"Deleting path:  {path}\")\n",
        "            info(f'Deleing path: {path}')\n",
        "            if os.path.exists(path):\n",
        "                rt = !rm -r \"$path\"\n",
        "                if rt:\n",
        "                    error(lines = rt)\n",
        "                    list_lines(rt)\n",
        "            else:\n",
        "                error(f\"{path} doesn't exist.\")\n",
        "                continue\n",
        "            if process_backup:\n",
        "                for i in range(1,4):\n",
        "                    pt = getbackup(path, bak_index = i)\n",
        "                    if not pt[0] in delpath and os.path.exists(pt[1]):\n",
        "                        pt = pt[1]\n",
        "                        if v:\n",
        "                            print(f\"Deleting path: {pt}\")\n",
        "                        info(f'Deleing file: {pt}')\n",
        "                        rt = !rm -r \"$pt\"\n",
        "                        if rt:\n",
        "                            error(lines = rt)\n",
        "                            list_lines(rt)\n",
        "                    else:\n",
        "                        warning(f\"Backup path: {pt} doesn't exist.\") \n",
        "        return\n",
        "\n",
        "    def is_cp(name):\n",
        "        return True if contains(checkpoint, name) else False\n",
        "\n",
        "    def del_cp(path):\n",
        "        p0 = f\"{path}/{checkpoint}\"\n",
        "        if os.path.exists(p0):\n",
        "            !rm -r \"$p0\"\n",
        "\n",
        "    def dircontent(path):\n",
        "        del_cp(path)\n",
        "        return os.listdir(path)\n",
        "\n",
        "    sizeDiffers = (1,'Size differs')\n",
        "    doesntExist = (2,\"Doesn't Exist\")\n",
        "    emptySizeLimit = 40000\n",
        "\n",
        "    class Sync_Status:\n",
        "        def __init__(self, path, src: int, message = '', name1 = '', name2 = '', size1 = '', size2 = '', status = doesntExist):\n",
        "            self.path = path\n",
        "            self.src = src\n",
        "            self.message = message\n",
        "            self.name1 = name1\n",
        "            self.name2 = name2\n",
        "            self.size1 = size1\n",
        "            self.size2 = size2\n",
        "            self.status = status\n",
        "\n",
        "    def compare_dirs(first, second, sync = False, syncNames = False, delEmpty = False):\n",
        "        info(f'Comparing sync status.\\nFirst path: {first}\\nSecond path: {second}')\n",
        "        if first and os.path.exists(first) and second and os.path.exists(second):\n",
        "            del_cp(first)\n",
        "            del_cp(second)\n",
        "            content1 = os.listdir(first)\n",
        "            content2 = os.listdir(second)\n",
        "            content1.sort()\n",
        "            content2.sort()\n",
        "            synced = []\n",
        "            sync_list: List[Sync_Status] = []\n",
        "            emty1 = emty2 = 0\n",
        "            if content1:\n",
        "                ln1 = len(content1)\n",
        "                ln2 = len(content2)\n",
        "                print(\"         {:<74}{:^43} {:^12}{:^12}{:^14}\\n\".format(\"In Dir 1\", \"In Dir 2\", \"Size in 1\",  \"Size in 2\", 'Sync Status'))\n",
        "                for item in content1:\n",
        "                    path1 = f\"{first}/{item}\"\n",
        "                    path2 = f\"{second}/{item}\"\n",
        "                    size1_raw= pathsize(path1)\n",
        "                    size1 = data_str(size1_raw)\n",
        "                    size2 = \"\"\n",
        "                    exists2 = False\n",
        "                    status2 = ''\n",
        "                    synced_ = 'Synced'\n",
        "                    unsynced_ = 'Unsynced'\n",
        "                    recheck = ''\n",
        "                    if delEmpty and size1_raw <= emptySizeLimit:\n",
        "                        !rm -r \"$path1\"\n",
        "                        ln1 -= 1\n",
        "                        info(f\"Empty directory deleted {path1}\")\n",
        "                        emty1 += 1\n",
        "                        size1 = 0\n",
        "\n",
        "                    if item in content2:        \n",
        "                        exists2 = True \n",
        "                        status2 = \"Exists\"\n",
        "                        content2.remove(item)\n",
        "\n",
        "                    else:\n",
        "                        recheck = research_name(item, content2)\n",
        "                        if recheck:\n",
        "                            exists2 = True\n",
        "                            content2.remove(recheck)\n",
        "                            path2 = f\"{second}/{recheck}\"\n",
        "                            status2 = f'[{recheck}]'\n",
        "                            info(f\"{item} exists as {recheck} in 2.\")\n",
        "\n",
        "                    if exists2:\n",
        "                        size2_raw = pathsize(path2)\n",
        "                        if delEmpty and size2_raw <= emptySizeLimit:\n",
        "                            !rm -r \"$path2\"\n",
        "                            ln2 -= 1\n",
        "                            info(f\"Empty directory deleted {path2}\")\n",
        "                            emty2 += 1            \n",
        "                            continue\n",
        "                          \n",
        "                        if recheck and syncNames:\n",
        "                            info(f\"Renaming {recheck} to {item}\")\n",
        "                            p0 = f\"{second}/{recheck}\"\n",
        "                            p1 = f\"{second}/{item}\"\n",
        "                            ot = !mv \"$p0\" \"$p1\"\n",
        "                            if ot:\n",
        "                                error(ot)\n",
        "                            else:\n",
        "                                path2 = p1\n",
        "                                status2 = 'Renamed'\n",
        "                                info(f\"Item {recheck} renamed to {item} in 2.\")\n",
        "\n",
        "\n",
        "                        size2 = data_str(size2_raw)\n",
        "                        diff = False if abs(size1_raw - size2_raw) <= 50000 else True\n",
        "                        if not diff:\n",
        "                            msg = \"    {:<80}{:^40}{:>12}{:>12}{:^20}\".format(item, status2, size1, size2, synced_)\n",
        "                            synced.append(msg)\n",
        "                        else: \n",
        "                            s_status = sizeDiffers[1]\n",
        "                            msg = \"{:<80}{:^40}{:>12}{:>12}{:^20}\".format(item, status2, size1, size2, s_status)\n",
        "                            if  size1_raw > size2_raw:\n",
        "                                status = Sync_Status(path= path1, src= 1, message= msg, status= sizeDiffers)\n",
        "                                info(f\"An item added to the sync list 1: {path1}, size differs in path 2.\")\n",
        "                            else:\n",
        "                                status = Sync_Status(path= path2, src= 2, message= msg, status= sizeDiffers)\n",
        "                                info(f\"An item added to the sync list 2: {path2}, size differs in path 1.\")\n",
        "                            sync_list.append(status)\n",
        "                    else:\n",
        "                        if not size1:\n",
        "                            continue\n",
        "                        status2 = ''\n",
        "                        s_status = doesntExist[1]\n",
        "                        msg = \"{:<80}{:^40}{:>12}{:>12}{:^20}\".format(item, status2, size1, size2, s_status )\n",
        "                        status = Sync_Status(path= path1, src= 1, message= msg, status= doesntExist)\n",
        "                        sync_list.append(status)\n",
        "                        info(f\"An item added to the sync list 1: {path1}, doesn't exist in path 2.\")\n",
        "\n",
        "                if content2:\n",
        "                    for item in content2:                    \n",
        "                        path2 = f'{second}/{item}'\n",
        "                        size2_raw =  pathsize(path2, False)\n",
        "                        if delEmpty and size2_raw <= emptySizeLimit:\n",
        "                            !rm -r \"$path2\"\n",
        "                            info(f\"Empty directory deleted {path2}\")\n",
        "                            emty2 += 1\n",
        "                            ln2 -= 1\n",
        "                            continue          \n",
        "                        size2 = data_str(size2_raw)\n",
        "                        msg = \"{:<80}{:^40}{:>12}{:>12}{:^20}\".format(\"\", item, '', size2, \"Doesn't Exist\")\n",
        "                        status = Sync_Status(path= path2, src= 2, message= msg, status= doesntExist)\n",
        "                        sync_list.append(status)\n",
        "                        info(f\"An item added to the sync list 2: {path2}, doesn't exist in path 1.\")\n",
        "\n",
        "                for item in synced:\n",
        "                    print(item)\n",
        "                    info(item)\n",
        "\n",
        "                if sync_list:\n",
        "                    sync_list.sort(key= lambda obj: obj.status[0])\n",
        "                    for i in range(len(sync_list)):\n",
        "                        item = sync_list[i]\n",
        "                        msg = f\"{str(i + 1)+' - ' if sync else '    '}{item.message}\"\n",
        "                        print(msg)\n",
        "                        info(item.message)\n",
        "\n",
        "                msg = f\"\\nTotal items in path 1: {ln1}   Total items in path 2:  {ln2}   Unsynced items: {len(sync_list)}.\\n\"\n",
        "                msg += f\"{f'Deleted empty folders in path 1:  {emty1}  ' if emty1 else ''}{f'Deleted empty folders in path 2:  {emty2}' if emty2 else ''}\\n\"\n",
        "                info(msg)\n",
        "                print(msg)\n",
        "\n",
        "                if sync and sync_list:\n",
        "                    print('Enter a selection for the synchronization:  e.g. i1, i2, i1-i5\\n')\n",
        "                    inp = input().strip()\n",
        "                    if (ext(inp) or no(inp)):\n",
        "                        return\n",
        "                    rngs = []  \n",
        "                    if inp == '.':\n",
        "                        rngs.extend(range(len(sync_list)))\n",
        "                    else:\n",
        "                        selects = inp.split(',')\n",
        "                        for select in selects:\n",
        "                            try:          \n",
        "                                if '-' in select:\n",
        "                                    splt = select.split('-')\n",
        "                                    s = int(splt[0]) - 1\n",
        "                                    e = int(splt[1])\n",
        "                                    rngs.extend(range(s, e))\n",
        "                                else:\n",
        "                                    rngs.append(int(select) - 1)\n",
        "                            except Exception as e:\n",
        "                                error(str(e))\n",
        "                                continue\n",
        "                    msg = f\"Syncing {first} with {second}.\\nTotal copying items: {len(rngs)}\"\n",
        "                    info(msg)\n",
        "                    print(msg)\n",
        "                    for i in rngs:\n",
        "                        p0 = sync_list[i].path\n",
        "                        p1 = second if sync_list[i].src == 1 else first\n",
        "                        print(f\"Copying: {os.path.basename(p0)} to {p1}\")\n",
        "                        info(f\"Copying: {os.path.basename(p0)} to {p1}\")\n",
        "                        !rsync --size-only -P -h -r \"$p0\" \"$p1\"\n",
        "                print(\"\\n.............\\n    Done\\n\")\n",
        "        else:\n",
        "            msg = f\"{first} {'exists' if os.path.exists(first) else 'does not exist'}\\n{second} {'exists' if os.path.exists(second) else 'does not exist'}\"\n",
        "            error(msg)\n",
        "\n",
        "    def research_name(key, content2):\n",
        "        key = key.strip()\n",
        "        if key:\n",
        "            key = os.path.splitext(key)[0]\n",
        "            keytrans = transstring(key)\n",
        "            ln = len(keytrans)\n",
        "            if ln >= 15:\n",
        "                for i in range(len(content2)):\n",
        "                    trans = transstring(os.path.splitext(content2[i])[0])\n",
        "                    ln1 = len(trans)\n",
        "                    if ln1 < 15:\n",
        "                        continue\n",
        "                    if ln1 <= ln:\n",
        "                        n0 = trans  \n",
        "                        n1 = keytrans\n",
        "                    else:\n",
        "                        n0 = keytrans\n",
        "                        n1 = trans\n",
        "                    if contains(n1, n0):\n",
        "                        return content2[i]\n",
        "        return False\n",
        "\n",
        "    def mt(path, bd = None, ad = None, backup = False, prompt = False):\n",
        "        if not (bd or ad):\n",
        "            return\n",
        "        info(f'Deleing files dated before {datetime.fromtimestamp(bd).strftime(\"%Y-%m-%d\")} in {path}')\n",
        "        files = next(os.walk(path))[2]\n",
        "        check = bd and ad\n",
        "        filter = []\n",
        "        for file in files:\n",
        "            p0 = os.path.join(path, file)\n",
        "            md = os.path.getmtime(p0)\n",
        "            if (check and md <= bd and md >= ad) or (bd and md <= bd) or (ad and md >= ad):\n",
        "                dstr = datetime.fromtimestamp(md).strftime('%Y-%m-%d')\n",
        "                size = data_str(os.path.getsize(p0))\n",
        "                msg = f'{dstr} - {size} {file}'\n",
        "                info(msg)\n",
        "                print(msg)\n",
        "                if prompt:\n",
        "                    filter.append(file)\n",
        "                    continue         \n",
        "                info(f\"Deleting {p0}..\")\n",
        "                rm(p0, backup, False)\n",
        "        if prompt:\n",
        "            rm(delpath= path, process_backup= backup, content= filter)\n",
        "        print('..... Done .....\\n')\n",
        "\n",
        "    def check_sd_base(path):\n",
        "        sch = re.search(sd_re, path)\n",
        "        if sch:\n",
        "            p0 = sch.group()  \n",
        "            if os.path.exists(p0):\n",
        "                return p0\n",
        "        return False\n",
        "\n",
        "    def makedirs(path, backup = False):\n",
        "        if path:\n",
        "          info(f\"Creating dir: {path}\")\n",
        "          os.makedirs(path, exist_ok = True)\n",
        "        if backup:\n",
        "            for i in range(1, 4):\n",
        "                nd = getbackup(path, bak_index = i)\n",
        "                np = nd[1]\n",
        "                check = check_sd_base(np)\n",
        "                if check:\n",
        "                    info(f\"Creating backup dir: {np}\")\n",
        "                    os.makedirs(np, exist_ok = True)\n",
        "                else:\n",
        "                    warning(f\"{nd[0]} doesn't exist.\")\n",
        "\n",
        "###############\n",
        "##### CSV #####\n",
        "\n",
        "if config.csvtoolsenabled:\n",
        "    import csv  \n",
        "    def wcsv(header, data, file, quoting = csv.QUOTE_MINIMAL):\n",
        "        if data:\n",
        "            islist = isinstance(data, list)\n",
        "            if islist:\n",
        "                datadict = isinstance(data[0], dict)\n",
        "            else:\n",
        "                datadict = isinstance(data, dict)\n",
        "\n",
        "            with open(file, 'w', newline=\"\") as csvfile:\n",
        "                if  datadict:\n",
        "                    writer = csv.DictWriter(csvfile, fieldnames = header, quoting=csv.QUOTE_MINIMAL, escapechar=' ')\n",
        "                    writer.writeheader()\n",
        "                else:\n",
        "                    writer = csv.writer(csvfile, quoting = quoting, escapechar=' ')\n",
        "                    writer.writerow(header)\n",
        "                if islist:  \n",
        "                    writer.writerows(data)\n",
        "                else :\n",
        "                    writer.writerow(data)\n",
        "        else:\n",
        "            print(\"wcsv error: data is empty.\")\n",
        "\n",
        "#################\n",
        "###### XML ######\n",
        "\n",
        "if config.xmltoolsenabled:\n",
        "    import ast\n",
        "    from bs4 import BeautifulSoup\n",
        "    propertyvalue = lambda item, tag = \"\":(item.get(tag) if tag else item.text) if item else \"\"\n",
        "\n",
        "    def xmltest(items):\n",
        "        if not items:\n",
        "            print(\"No items\")\n",
        "            return\n",
        "        else:\n",
        "            print(f\"Total items: {len(items)}\\nSample:\\n {items[round(len(items)/2)]}\")\n",
        "\n",
        "    valtl = \"x\"\n",
        "    elre = r\"(?<=<>).*(?=<\\/>)\"\n",
        "\n",
        "    def xmlview(file, element, attr = \"\"):\n",
        "        items = xmlcall(file, element)\n",
        "        print(f\"All items: {len(items)}\\n\")\n",
        "        for i in range(len(items)):\n",
        "            val = items[i].text if not attr else items[i].get(attr)\n",
        "            print(f\"Item {i:<5}->   {val:<10}\")\n",
        "        return items\n",
        "\n",
        "    def xmledit(file, element, value= None, numbers = False, savefile = None):\n",
        "        if os.path.isfile(file):\n",
        "            if not savefile:\n",
        "                savefile = file\n",
        "            count = subs = 0\n",
        "            with open(file, 'r') as xfile:\n",
        "                target = r'(?<=<' + element + r'>).*(?=<\\/'+ element + '>)'\n",
        "                txt = xfile.read();\n",
        "\n",
        "                if value:\n",
        "                    newtxt = txt\n",
        "                    print(f\"{'Updating values in:':>19} <{element}>\\n{'Reevaluation:':>19} {value} (x: old value)\\n\")\n",
        "                else:\n",
        "                    print(f\"Values in <{element}>:\\n\")\n",
        "\n",
        "                mchs = re.findall(target, txt)\n",
        "                if mchs:\n",
        "                    matches = set(mchs) if value else mchs\n",
        "                    count = len(matches)\n",
        "                    i = 0\n",
        "                    for mch in matches:\n",
        "                        if value:\n",
        "                            oldval = mch if not numbers else ast.literal_eval(mch)\n",
        "                            newval = eval(value, {\"x\": oldval})\n",
        "                            thistarget = target.replace(\".*\", mch)\n",
        "                            sub = re.subn(thistarget, str(newval), newtxt)\n",
        "                            newtxt = sub[0]\n",
        "                            subs += sub[1]\n",
        "                            print( f\"{i:<4}- {str(mch):<15} {'->':<15} {str(newval):<15}Subs {sub[1]}\")\n",
        "                        else:\n",
        "                            print(f\"{i:<4}- {mch:<10}\")\n",
        "                        i += 1\n",
        "                if value:\n",
        "                    with open(savefile, 'w') as wfile:\n",
        "                        wfile.write(newtxt)\n",
        "                        print(f\"\\nTotal matches: {count}     Values changed: {subs}\\n\")\n",
        "                        return True\n",
        "                else:\n",
        "                    print(f\"\\nTotal values: {count}\\n\")\n",
        "\n",
        "\n",
        "    def xmlcall(file, element, callback = None):\n",
        "        print(f\"Reading xml file: {file}\")\n",
        "        if os.path.isfile(file):\n",
        "            with open(file, 'r') as f:\n",
        "                data = f.read()\n",
        "                print(f\"Reading done.\\nLength of read data is {len(data)} bytes.\")\n",
        "\n",
        "        else:\n",
        "            print(\"xmlcall error: provided file path isn't there.\")\n",
        "            return\n",
        "\n",
        "        print(f\"Scraping xml from the file.\")\n",
        "        xml_data = BeautifulSoup(data, \"xml\")\n",
        "        if xml_data == None:\n",
        "            print(f\"xmlcall error: BS4 counldn't scrape xml data from the file. Data is None.\")\n",
        "            return\n",
        "        if len(xml_data) == 0:\n",
        "            print(\"xmlcall error: BS4 returned empty data. len(xml_data) is 0.\")\n",
        "            return\n",
        "\n",
        "        items = xml_data.find_all(element)\n",
        "        if items == None:\n",
        "            print(f\"xmlcall error: BS4 counldn't read requested items with this node name: {element}\")\n",
        "            return\n",
        "        if len(items) == 0:\n",
        "            print(f\"xmlcall error: BS4 returned empty result for requested items with this node name: {element}\")\n",
        "            return\n",
        "        print(f\"{len(items)}\")\n",
        "        return callback(items) if callback else items\n",
        "\n",
        "########################\n",
        "####### Display ########\n",
        "\n",
        "\n",
        "layout_r = {'padding-left':'100px','flex_flow':'row','align_items':'flex-start','width':'95%','justify_content':'space-around'}\n",
        "\n",
        "progress_bar = widgets.FloatProgress(\n",
        "      value=0,\n",
        "      min=0,\n",
        "      max=100,\n",
        "      step=0.1,\n",
        "      bar_style='info',\n",
        "      orientation='horizontal',\n",
        "      layout=layout_15)\n",
        "\n",
        "done_label = widgets.Label(\n",
        "    value = f\"\",\n",
        "    layout = layout_2\n",
        ")\n",
        "\n",
        "progress_label = widgets.Label(\n",
        "    value = f\"0%\",\n",
        "    layout = layout_1\n",
        ")\n",
        "\n",
        "download_label = widgets.Label(\n",
        "    value = f\"Downloading\",\n",
        "    layout = layout_r\n",
        ")\n",
        "\n",
        "display_row = widgets.Box([ empty_label_2, done_label, empty_label_1, progress_label, progress_bar, empty_label_2], layout = layout_r)\n",
        "\n",
        "########################"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "z7vNZ0vapPZ6"
      },
      "source": [
        "#### Scraping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UEZO1IwTKaez"
      },
      "outputs": [],
      "source": [
        "#@title  { form-width: \"2%\" }\n",
        "#@markdown\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "\n",
        "Base = \"\" #@param {type:\"string\"}\n",
        "Target = \"\" #@param {type:\"string\"}\n",
        "Limit = 0 #@param {type:\"number\"}\n",
        "\n",
        "def scrape_posts(link_base, limit = 0, target_class = '', id_var = ''):\n",
        "    limit = 100 if limit == 0 else limit\n",
        "    var = f\"?{id_var}=\" if id_var else ''\n",
        "    scrape = {}\n",
        "    posts = []\n",
        "    for i in range(limit + 1):\n",
        "        time.sleep(0.1)\n",
        "        url = f\"{link_base}/?{var}{i}\"\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "            page = soup.find('div', {\"class\": target_class})\n",
        "            if page:\n",
        "                print(f'Post found: {url}')\n",
        "                posts.append(str(page))\n",
        "                continue\n",
        "        print(f'No Post:   {url}')\n",
        "\n",
        "    if posts:\n",
        "        scrape['posts'] = posts\n",
        "        return scrape\n",
        "    else:\n",
        "        print('No posts found.')\n",
        "        return ''\n",
        "\n",
        "json_obj = scrape_posts(Base, target_class = Target, limit = Limit)\n",
        "write_json(json_obj)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MFg7sP7rpYxj"
      },
      "source": [
        "#### Json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "G34uOfCufUA8"
      },
      "outputs": [],
      "source": [
        "#@title  { form-width: \"2%\" }\n",
        "#@markdown ##### <b>&nbsp;&nbsp;&nbsp;Target:&nbsp;&nbsp;&nbsp;json_obj<b>\n",
        "\n",
        "Read = 100\n",
        "Write = 200\n",
        "\n",
        "Operation = Write #@param [\"Read\", \"Write\"] {type:\"raw\"}\n",
        "File = \"/content/newfile-img-migrated.json\" #@param {type:\"string\"}\n",
        "Encoding = 'utf-8-sig' #@param ['utf-8-sig', 'utf8'] {type:\"string\"}\n",
        "\n",
        "\n",
        "if Operation == Read and File:\n",
        "    json_obj = read_json(File, Encoding)\n",
        "else:\n",
        "    Source = json_obj #@param {type:\"raw\"}\n",
        "    if File: \n",
        "        write_json(Source, File)\n",
        "    else:\n",
        "        write_json(Source)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SKGyUmcqpdni"
      },
      "source": [
        "#### Scan Json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "JXTze3-xfUA9"
      },
      "outputs": [],
      "source": [
        "#@title  { form-width: \"2%\" }\n",
        "#@markdown\n",
        "\n",
        "Source = json_obj #@param {type:\"raw\"}\n",
        "Root = \"posts\" #@param {type: \"string\"}\n",
        "InnerKey = \"thumb\" #@param {type: \"string\"}\n",
        "Expression = None #@param {type: \"raw\"}\n",
        "Substitute = \"\" #@param {type: \"string\"}\n",
        "Limit = 0 #@param {type: \"raw\"}\n",
        "Callback = check_ok #@param [\"None\"] {type:\"raw\", allow-input: true}\n",
        "Print = True #@param {type:\"boolean\"}\n",
        "\n",
        "def scan_json(scan_obj, limit = 0 , root = \"\" , key = \"\", exp = \"\", \n",
        "    replace = \"\", callback = None, v = False):\n",
        "    toscan = scan_obj[root] if root else scan_obj\n",
        "    if type(toscan) == str:\n",
        "        toscan = [toscan]\n",
        "\n",
        "    if type(limit) == str:\n",
        "        if '-' in limit:\n",
        "            splt = limit.split('-')\n",
        "            s = int(splt[0])\n",
        "            e = int(splt[1])\n",
        "        else:\n",
        "            s = 0\n",
        "            e = int(limit)        \n",
        "    elif limit:\n",
        "        s = 0\n",
        "        e = limit\n",
        "    else:\n",
        "        s = 0\n",
        "        e = len(toscan)\n",
        "\n",
        "    if replace and exp:\n",
        "        print(f\"Substituting \\\"{exp}\\\" with \\\"{replace}\\\"\")\n",
        "        for i in range(s, e):\n",
        "            print(f\"\\nPost {i}\")\n",
        "            element = toscan[i][key] if key else toscan[i] \n",
        "            scaned = re.subn(exp, replace, element)\n",
        "            if scaned:\n",
        "                print(f\"Substitutions: {scaned[1]}\")\n",
        "                if key:\n",
        "                    toscan[i][key] = scaned[0]\n",
        "                else:\n",
        "                    toscan[i] = scaned[0]\n",
        "            else:\n",
        "                print(f\"No subtitutions.\")\n",
        "        return\n",
        "\n",
        "    for i in range(s, e):\n",
        "        print(f\"Item {i}\")\n",
        "        element = toscan[i][key] if key else toscan[i] \n",
        "        mchs = re.findall(exp, element) if exp else [element]\n",
        "        if mchs:\n",
        "            if callback:\n",
        "                for mch in mchs:\n",
        "                    if v:\n",
        "                        print(f\" {mch}\")\n",
        "                        try:\n",
        "                            callback(mch)\n",
        "                        except (Exception, KeyboardInterrupt) as e:\n",
        "                            print(str(e))\n",
        "            else:\n",
        "                for item in mchs:\n",
        "                    print(item)          \n",
        "        else:\n",
        "            print(\" No matches.\")\n",
        "        print()\n",
        "\n",
        "\n",
        "if Source:\n",
        "    scan_json(Source, Limit, Root, InnerKey, Expression, Substitute, Callback, Print)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6YLVTJNfplvp"
      },
      "source": [
        "#### Check Json Item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "m-Qt-7Q_edZM"
      },
      "outputs": [],
      "source": [
        "#@title  { form-width: \"2%\" }\n",
        "#@markdown\n",
        "\n",
        "obj = json_obj['posts'][103] \n",
        "obj"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "B6HejtQApuym"
      },
      "source": [
        "#### Scrape Item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UcFPz7JYedZN"
      },
      "outputs": [],
      "source": [
        "#@title  { form-width: \"2%\" }\n",
        "#@markdown\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "soup = BeautifulSoup(t, 'html.parser')\n",
        "target_class = 'browse-text'\n",
        "el = soup.find('div', {\"class\": target_class})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xFW-4765p_B3"
      },
      "source": [
        "#### Scan Item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "dgsuNiKmedZN"
      },
      "outputs": [],
      "source": [
        "#@title  { form-width: \"2%\" }\n",
        "#@markdown\n",
        "\n",
        "\n",
        "hashtags = set()\n",
        "hashtag_re = r\"#[^\\s<>\\/]*(?=\\s|<|>)\"\n",
        "mchs = re.findall(hashtag_re, str(el), re.MULTILINE)\n",
        "if mchs:\n",
        "    for m in mchs:\n",
        "        hashtags.add(m)\n",
        "\n",
        "for m in hashtags:\n",
        "    print(m)\n",
        "\n",
        "str(el)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ROGVy4yKqDgI"
      },
      "source": [
        "#### FTP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "cellView": "form",
        "id": "EGN-NwZNEAVf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".ftpquota\n",
            "td_log.txt\n"
          ]
        }
      ],
      "source": [
        "#@title  { form-width: \"2%\" }\n",
        "#@markdown\n",
        "\n",
        "if 'ftputil' in sys.modules:\n",
        "    import ftputil\n",
        "else:\n",
        "    ftputil = None\n",
        "\n",
        "List = 0\n",
        "Upload = 10\n",
        "Download = 20\n",
        "BlukUploadFromURLs = 11\n",
        "CreateM3UFromFiles = 30\n",
        "\n",
        "Source = \"/content/c:/td/logs/transfer/done/\" #@param {type: \"string\"}\n",
        "Target = '/domains/ghirasalkhaeer.com' #@param {type: \"string\"}\n",
        "Operation = Upload #@param [\"List\", \"Upload\",  \"Download\", \"BlukUploadFromURLs\", \"CreateM3UFromFiles\"] {type: \"raw\"}\n",
        "if Env_Colab:\n",
        "    done_path = '/content/done'\n",
        "else:\n",
        "    done_path = f\"{app_base}/transfer/done\"\n",
        "\n",
        "os.makedirs(done_path, exist_ok = True)\n",
        "total_size = 0\n",
        "total_str = \"\"\n",
        "done = 0\n",
        "patch_size = 0\n",
        "\n",
        "ftpinfo = f\"ftp://{config.ftpuser}:'{config.ftppassword}'@{config.ftphost}\"\n",
        "\n",
        "def ls_ftp(dir = \"\", size = False):\n",
        "    if not ftputil:\n",
        "        print('ftputil undefined')\n",
        "        return\n",
        "    \n",
        "    total_size = 0\n",
        "    items = []\n",
        "    with ftputil.FTPHost(config.ftphost, config.ftpuser, config.ftppassword) as ftp:\n",
        "        if not dir:\n",
        "            dir = ftp.curdir\n",
        "        path, dirs, files = next(ftp.walk(dir))\n",
        "        files.sort()\n",
        "        dirs.sort()\n",
        "\n",
        "        for name in dirs:\n",
        "            item = f\"{path}/{name}\"\n",
        "            items.append(item) \n",
        "\n",
        "        for name in files:\n",
        "            item = f\"{path}/{name}\"\n",
        "            items.append(item)\n",
        "\n",
        "        for i in range(len(items)):\n",
        "            print(f\"{str(i+1).ljust(3)} - {items[i]}\")\n",
        "\n",
        "        if total_size:\n",
        "            print(f\"\\nTotal size: {data_str(total_size)}\")\n",
        "\n",
        "def update_upload(chunk):\n",
        "    global done, total_size, progress_bar, progress_label, done_label\n",
        "    done += len(chunk)\n",
        "    progress = round(done*100/total_size, 1)\n",
        "    progress_bar.value = progress\n",
        "    if progress == 100:\n",
        "        progress_bar.bar_style = 'success'\n",
        "    done_label.value = f\"{data_str(done)} {total_str}\"\n",
        "    progress_label.value = f\"{progress}%\"\n",
        "\n",
        "def update_download(chunk):\n",
        "    global done, download_label, patch_size \n",
        "    patch = len(chunk)\n",
        "    done += patch\n",
        "    result = ' -  Transfered Successfully' if patch < patch_size else ''\n",
        "    download_label.value = f\"Transfered {data_str(done)} {result}\"\n",
        "    if not patch_size:\n",
        "        patch_size = patch\n",
        "\n",
        "def uploadtoftp(source, saveto, progresscall = None, dircontentonly = False):\n",
        "    if os.path.isdir(source):\n",
        "        uploaddirtoftp(source, saveto, progresscall, dircontentonly)\n",
        "    elif os.path.isfile(source):\n",
        "        uploadfiletoftp(source, saveto, progresscall = None)\n",
        "\n",
        "def uploadfiletoftp(source, saveto, progresscall = None):\n",
        "    if not ftputil:\n",
        "        print('ftputil undefined')\n",
        "        return\n",
        "    with ftputil.FTPHost(config.ftphost, config.ftpuser, config.ftppassword) as ftp:\n",
        "        ftp.upload_if_newer(source, saveto)\n",
        "        \n",
        "def uploaddirtoftp(source, saveto, progresscall = None, dircontentonly = False): \n",
        "    if not os.path.exists(source):\n",
        "        print(f\"Error: the source path doesn't exist.\\nSource{source}\")\n",
        "        return\n",
        "    print(f\"Uploading: {source} to remote ftp path: {saveto}\")\n",
        "    uploaddir = os.path.isdir(Source)\n",
        "    targetpath = f'{saveto}/{os.path.basename(source)}' if uploaddir and not dircontentonly else saveto\n",
        "    mkdir = f\" mkdir -p -f '{targetpath}';\"\n",
        "    if uploaddir:\n",
        "        cmd = f'lftp {ftpinfo} -e \"set ftp:ssl-allow no; {mkdir}; mirror -R \\'{source}\\' \\'{targetpath}\\' ; quit;\"'\n",
        "    else: \n",
        "        cmd = f'lftp {ftpinfo} -e \"set ftp:ssl-allow no; {mkdir}; put -O \\'{targetpath}\\' \\'{source}\\' ; quit;\"'\n",
        "    print(f\"Command: {cmd}\")\n",
        "    !$cmd\n",
        "\n",
        "def downloadfromftp(source, saveto, progresscallback = None):\n",
        "    cmd = f'lftp {ftpinfo} -e \"set ftp:ssl-allow no; mirror \\'{source}\\' \\'{saveto}\\';\"'\n",
        "    getcommand = 'get'\n",
        "    !$cmd\n",
        "\n",
        "def downloadfilefromftp(path, savepath, progresscallback = None):\n",
        "    global total_size, total_str\n",
        "    if not ftputil:\n",
        "        print('ftputil undefined.')\n",
        "        return\n",
        "    total_size = 0\n",
        "    total_str = ''\n",
        "    with ftputil.FTPHost(config.ftphost, config.ftpuser, config.ftppassword) as ftp:\n",
        "        target = f\"{savepath}/{os.path.basename(path)}\"\n",
        "        os.makedirs(target, exist_ok= True)\n",
        "        ftp.download_if_newer(path, target, callback = progresscallback)\n",
        "        if has_size(target):\n",
        "            !mv \"$target\" \"$savepath\"\n",
        "\n",
        "def downloaddirfromftp():\n",
        "    pass\n",
        "\n",
        "def bulkuploadfromurlstoftp(urllist, uploadpath):\n",
        "    if urllist:\n",
        "        os.makedirs('ftpcache', exist_ok= True)\n",
        "        for url in urllist:\n",
        "            !wget -P 'ftpcache' \"$url\" -q \n",
        "        uploadtoftp(\"/content/ftpcache\", uploadpath, dircontentonly= True)\n",
        "\n",
        "def createm3ufromftpdir(ftpsource, filetypes= None):\n",
        "    if ftpsource:\n",
        "        with ftputil.FTPHost(config.ftphost, config.ftpuser, config.ftppassword) as ftp:\n",
        "            path, dirs, files = next(ftp.walk(ftpsource))\n",
        "            for file in files:\n",
        "                print(file)\n",
        "            #if filetypes:\n",
        "\n",
        "if Source:\n",
        "    if Operation == Upload:\n",
        "        uploadtoftp(Source, Target)\n",
        "\n",
        "    elif Operation == BlukUploadFromURLs:\n",
        "        bulkuploadfromurlstoftp(Source, Target)\n",
        "\n",
        "    elif Operation == CreateM3UFromFiles:\n",
        "        createm3ufromftpdir(Source, filetypes= Target)\n",
        "\n",
        "    elif Operation == List:\n",
        "       ls_ftp(dir = Target, size = False) \n",
        "    else:\n",
        "        display(download_label)\n",
        "        downloadfromftp(Source, Target)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6S4yZ1TvqR39"
      },
      "source": [
        "#### Files Manager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ufP2IYmD8O3z"
      },
      "outputs": [],
      "source": [
        "#@title  { form-width: \"2%\" }\n",
        "#@markdown\n",
        "\n",
        "Test_Drive = 11\n",
        "Copy = 100\n",
        "Move = 200\n",
        "Delete =  300 \n",
        "To_Replace = 301 \n",
        "\n",
        "NewFolder = 500\n",
        "Rename = 400\n",
        "\n",
        "Compare = 600  \n",
        "Sync = 601\n",
        "CheckSize = 602\n",
        "\n",
        "Clean = 701 \n",
        "\n",
        "Zip = 800\n",
        "Unzip = 801\n",
        "\n",
        "Operation = Test_Drive #@param [\"Test_Drive\", \"Copy\", \"Move\", \"Delete\", \"To_Replace\", \"Rename\", \"NewFolder\", \"Compare\", \"Sync\", \"CheckSize\", \"Zip\", \"Unzip\"] {type:\"raw\"}\n",
        "\n",
        "From_Path = \"\" #@param [\"\", \"/content/drive/Shareddrives/MV/Movies\", \"/content/drive/Shareddrives/MC/Music\", \"/content/drive/Shareddrives/TV/TV Shows\", \"/content/drive/Shareddrives/MVB1/Movies\", \"/content/drive/Shareddrives/MCB1/Music\", \"/content/drive/Shareddrives/TVB1/TV Shows\", \"/content/drive/Shareddrives/MVB2/Movies\", \"/content/drive/Shareddrives/TVB2/TV Shows\", \"/content/drive/Shareddrives/MCB2/Music\", \"/content/drive/Shareddrives/MVB3/Movies\", \"/content/drive/Shareddrives/MVB3/Music\", \"/content/drive/Shareddrives/TVB3/TV Shows\", \"/content/drive/MyDrive/Library/Movies\", \"/content/drive/MyDrive/Library/TV Shows\", \"/content/drive/MyDrive/Library/Music\"] {allow-input: true}\n",
        "To_Path = \"\"  #@param [\"\", \"/content/drive/Shareddrives/MV/Movies\", \"/content/drive/Shareddrives/MC/Music\", \"/content/drive/Shareddrives/TV/TV Shows\", \"/content/drive/Shareddrives/MVB1/Movies\", \"/content/drive/Shareddrives/MCB1/Music\", \"/content/drive/Shareddrives/TVB1/TV Shows\", \"/content/drive/Shareddrives/MVB2/Movies\", \"/content/drive/Shareddrives/TVB2/TV Shows\", \"/content/drive/Shareddrives/MCB2/Music\", \"/content/drive/Shareddrives/MVB3/Movies\", \"/content/drive/Shareddrives/MVB3/Music\", \"/content/drive/Shareddrives/TVB3/TV Shows\", \"/content/drive/MyDrive/Library/Movies\", \"/content/drive/MyDrive/Library/TV Shows\", \"/content/drive/MyDrive/Library/Music\"] {allow-input: true}\n",
        "\n",
        "Multi = False #@param {type:\"boolean\"}\n",
        "Backup = False #@param {type:\"boolean\"}\n",
        "Rename_ = False #@param {type:\"boolean\"}\n",
        "Movie_Name = False #@param {type:\"boolean\"}\n",
        "Show_Name = False #@param {type:\"boolean\"}\n",
        "Delete_Empty = False #@param {type: \"boolean\"}\n",
        "Use_Native = False #@param {type: \"boolean\"}\n",
        "Zip_Split = \"8g\" #@param {type: \"string\"}\n",
        "\n",
        "#@title ##### Zip\n",
        "\n",
        "def is_zip(name):\n",
        "    sch = re.search(ext_re, name)\n",
        "    if sch:\n",
        "        res = sch.group()\n",
        "        return res == '.zip' or res == '.gz' or res == '.rar' or res == '.7z'\n",
        "    return False  \n",
        "\n",
        "def zip(input, save: str = \"\", split = \"\", callback = None):\n",
        "    save = save.strip()\n",
        "    if input:\n",
        "        if not save:\n",
        "            save = f\"zipped-files-{nowstr(True)}.zip\"\n",
        "        else:  \n",
        "            if not (is_zip(save)):\n",
        "                save += \".zip\"\n",
        "        split_arg = f\" -s {split} \" if split else \"\"\n",
        "        print(f\"Zipping: {input}\\nTo: {save}\")\n",
        "        cm = f'zip -r -q {split_arg} \"{save}\" \"{input}\"'\n",
        "        print(cm)\n",
        "        !zip -r -q $split_arg \"$save\" \"$input\"\n",
        "        if has_size(save):\n",
        "            print(f'Done, check output: {save}')\n",
        "\n",
        "def unzip(input, save: str = \"\", callback = None):\n",
        "    save = save.strip()\n",
        "    if input:\n",
        "        print(f\"Unzipping: {input}\\nTo: {save}\")\n",
        "        saving = \"-d \" + f'\"{save}\"' if save else \"\"\n",
        "        !unzip \"$input\" $saving\n",
        "        print(f'Done, check output: {save}')\n",
        " \n",
        "def FolderSize(path):\n",
        "    print(f\"Checking size for path: {path}\")\n",
        "    size = pathsize(path, True)\n",
        "    print(f\"    {size}\")\n",
        " \n",
        "From_Path = From_Path.strip()\n",
        "To_Path = To_Path.strip()\n",
        "\n",
        "\n",
        "if Operation == Test_Drive:\n",
        "    if os.path.exists('drive/MyDrive'):\n",
        "        !echo \"This text is to test writing on drive.\" > drive_test.txt\n",
        "        !mv drive_test.txt drive/MyDrive \n",
        "    else:\n",
        "        print(\"Google Drive isn't mounted.\")\n",
        "\n",
        "elif Multi and (Operation < 310):\n",
        "    dirs = dircontent(From_Path)\n",
        "    try:\n",
        "        if 1 < Operation/Delete < 1.1 :\n",
        "            toreplace = True if Operation == To_Replace else False\n",
        "            rm(From_Path, Backup, toreplace, content= dirs)\n",
        "\n",
        "        elif From_Path and To_Path:\n",
        "            if Operation == Copy:\n",
        "                cp( from_path = From_Path, to_path = To_Path, backup = Backup, content= dirs, native = Use_Native)\n",
        "            elif Operation == Move:\n",
        "                mv( from_path = From_Path, to_path = To_Path, backup = Backup, content= dirs)\n",
        "\n",
        "    except KeyboardInterrupt as k:\n",
        "        k\n",
        "\n",
        "elif Operation == NewFolder:\n",
        "    makedirs(From_Path, Backup)\n",
        "\n",
        "elif  Operation == Compare:\n",
        "    compare_dirs(From_Path, To_Path, False, syncNames= Rename_, delEmpty = Delete_Empty)\n",
        "\n",
        "elif  Operation == Sync:\n",
        "    compare_dirs(From_Path, To_Path, True, syncNames= Rename_, delEmpty = Delete_Empty)\n",
        "\n",
        "elif Operation == CheckSize:\n",
        "    FolderSize(From_Path)\n",
        "\n",
        "elif Operation == Zip:\n",
        "    zip(From_Path, To_Path, split = Zip_Split)\n",
        "\n",
        "elif Operation == Unzip:\n",
        "    unzip(From_Path, To_Path) \n",
        "\n",
        "elif Operation == Rename:\n",
        "    rename(path= From_Path, newpath= To_Path, backup= Backup)\n",
        "\n",
        "elif Operation == Delete:\n",
        "    print(f\"Deleting: {From_Path}. Are you sure?                    Enter for confirm. \")\n",
        "    inpt = input()\n",
        "    if inpt == \"\" or inpt == \"y\":\n",
        "        rm(From_Path, Backup, False)\n",
        "\n",
        "elif Operation == To_Replace:\n",
        "    rm(From_Path, Backup, True)\n",
        "\n",
        "elif From_Path and To_Path:\n",
        "    if Operation == Move:\n",
        "        mv(from_path= From_Path, to_path= To_Path, backup = Backup)\n",
        "    elif Operation == Copy:\n",
        "        cp(from_path= From_Path, to_path= To_Path, backup = Backup, native = Use_Native)\n",
        "\n",
        "#release()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qMdawGdeqW-R"
      },
      "source": [
        "#### Check Old Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oME4l8Q0fUA8"
      },
      "outputs": [],
      "source": [
        "#@title  { form-width: \"2%\" }\n",
        "#@markdown\n",
        "\n",
        "from datetime import datetime\n",
        "#/content/drive/Shareddrives/SM2/Library/TV Shows/Friends 1994/S01\n",
        "Path = \"\" #@param {type:\"string\"}\n",
        "Before_Date = \"2022-09-01\" #@param {type:\"date\"}\n",
        "After_Date = \"2022-08-10\" #@param {type:\"date\"}\n",
        "\n",
        "Process_Backup = True #@param {type:\"boolean\"}\n",
        "Confirm_Delete = False #@param {type:\"boolean\"}\n",
        "\n",
        "bd = datetime.strptime(Before_Date, '%Y-%m-%d').timestamp() if Before_Date else None\n",
        "ad = datetime.strptime(After_Date, '%Y-%m-%d').timestamp() if After_Date else None\n",
        "mt(Path, bd, ad, backup = Process_Backup, prompt = Confirm_Delete)\n",
        "release()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HGwP1gAeqe8L"
      },
      "source": [
        "#### Decode Unicode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BOh278e6C7f0"
      },
      "outputs": [],
      "source": [
        "#@title  { form-width: \"2%\" }\n",
        "#@markdown\n",
        "\n",
        "import unicodedata\n",
        "\n",
        "posts = scrape[\"posts\"]\n",
        "\n",
        "for i in range(len(posts)):\n",
        "    item = posts[i]\n",
        "    decoded = unicodedata.normalize('NFKD', item)\n",
        "    posts[i] = decoded\n",
        "  \n",
        "scrape[\"posts\"] = posts"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RnDs4d_gqibG"
      },
      "source": [
        "#### URL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3ET5E2Ad3fb2"
      },
      "outputs": [],
      "source": [
        "#@title  { form-width: \"2%\" }\n",
        "#@markdown\n",
        "\n",
        "import urllib\n",
        "\n",
        "Quote = 100\n",
        "Unquote = 200\n",
        "Operation = Unquote #@param [\"Quote\", \"Unquote\"] {type: \"raw\"}\n",
        "String = \"\" #@param {type: \"string\"}\n",
        "\n",
        "if Operation == Quote:\n",
        "    string = urllib.parse.quote(String)\n",
        "else:\n",
        "    string = urllib.parse.unquote(String)\n",
        "\n",
        "string"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2iPXJ-F-qmWz"
      },
      "source": [
        "#### MySQL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "acd6mFLVsOGG"
      },
      "outputs": [],
      "source": [
        "#@title  { form-width: \"2%\" }\n",
        "#@markdown\n",
        "\n",
        "import MySQLdb\n",
        "\n",
        "Ping = 10\n",
        "Connect = 20\n",
        "Query = 30\n",
        "Callback = 40\n",
        "CurlServer = 50\n",
        "\n",
        "Operation = Callback #@param [\"Ping\", \"Connect\", \"Query\", \"Callback\", \"CurlServer\"] {type:\"raw\"}\n",
        "\n",
        "MySQL_Host = \"5.2.85.161\" #@param {type:\"string\"}\n",
        "MySQL_Username = \"\" #@param {type:\"string\"}\n",
        "MySQL_Password = \"\" #@param {type:\"string\"}\n",
        "MySQL_DB = \"emasri_ghiras_prod\" #@param {type:\"string\"}\n",
        "Input = mysql_call #@param {type:\"string\"} {type:\"raw\"}\n",
        "\n",
        "def mysql_ensure(conn, v = False):\n",
        "    status = conn.stat()\n",
        "    if status.startswith(\"Lost\"):\n",
        "        print('Reconnecting.')\n",
        "        conn.ping(True)\n",
        "        if v:\n",
        "            print(conn.stat())\n",
        "    elif v:\n",
        "        print(status) \n",
        "\n",
        "def mysql_query(host, user, password, db, query):\n",
        "    with MySQLdb.connect(host, user, password, db, connect_timeout = 3306) as conn:\n",
        "        cur: MySQLdb.cursors.Cursor = conn.cursor()\n",
        "        cur.execute(query)\n",
        "        res = cur.fetchall()\n",
        "        conn.commit()\n",
        "        if res:\n",
        "            for item in res:\n",
        "                print(item)\n",
        "            return res\n",
        "        else:\n",
        "            print('Empty result.')\n",
        "            return None\n",
        "    \n",
        "def mysql_ping(host, user, password, db):\n",
        "    with MySQLdb.connect(host, user, password, db, connect_timeout = 3306) as conn:\n",
        "        conn: MySQLdb.Connection \n",
        "        conn.set_character_set('utf8')\n",
        "        return conn.ping()\n",
        "\n",
        "def mysql_connect(host, user, password, db):\n",
        "    conn: MySQLdb.Connection = MySQLdb.connect(host, user, password, db, connect_timeout = 3306)\n",
        "    return conn\n",
        "\n",
        "def mysql_callback(host, user, password, db, callback):\n",
        "    with MySQLdb.connect(host, user, password, db, connect_timeout = 3306) as conn:\n",
        "        conn: MySQLdb.Connection \n",
        "        conn.autocommit(True)\n",
        "        callback(conn)\n",
        "\n",
        "def mysql_call(mysql: MySQLdb.Connection):\n",
        "    status = mysql.stat()\n",
        "    if status.startswith(\"Lost\"):\n",
        "        print('Reconnecting.')\n",
        "        mysql.ping(True)\n",
        "        print(mysql.stat())\n",
        "    else:\n",
        "        print(status) \n",
        "\n",
        "    print(f\"Auto commit: {mysql.get_autocommit()}\")\n",
        "\n",
        "if Operation == Ping:\n",
        "    mysql_ping(MySQL_Host, MySQL_Username, MySQL_Password, MySQL_DB)\n",
        "\n",
        "elif Operation == Connect:\n",
        "    mysql: MySQLdb.Connection = mysql_connect(MySQL_Host, MySQL_Username, MySQL_Password, MySQL_DB)\n",
        "    mysql.ping(True)\n",
        "\n",
        "elif Operation == Query and Input:\n",
        "    mysql_query(MySQL_Host, MySQL_Username, MySQL_Password, MySQL_DB, Input)\n",
        "\n",
        "elif Operation == Callback and Input:\n",
        "    mysql_callback(MySQL_Host, MySQL_Username, MySQL_Password, MySQL_DB, Input)\n",
        "\n",
        "elif Operation == CurlServer:\n",
        "    !curl emasri.com &> /dev/null\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iPyyozXkqsT-"
      },
      "source": [
        "##### Data Template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "URnbyCmuK7QN"
      },
      "outputs": [],
      "source": [
        "#@title  { form-width: \"2%\" }\n",
        "#@markdown\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FwJT_c5Nqwzn"
      },
      "source": [
        "#### Callback\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UvlKpscPaOtK"
      },
      "outputs": [],
      "source": [
        "#@title  { form-width: \"2%\" }\n",
        "#@markdown\n",
        "\n",
        "def mysql_call(conn: MySQLdb.Connection):\n",
        "    pass\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0TAfMS9g5Okn"
      },
      "source": [
        "#### Wordpress Posts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "AiPXNLGKcDKI"
      },
      "outputs": [],
      "source": [
        "#@title  { form-width: \"2%\" }\n",
        "#@markdown #### Create posts data.\n",
        "\n",
        "posts = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "VUHr--s25Okn"
      },
      "outputs": [],
      "source": [
        "#@title  { form-width: \"2%\" }\n",
        "#@markdown\n",
        "\n",
        "from datetime import datetime, timezone, timedelta\n",
        "\n",
        "CreatePosting = 10\n",
        "Test_Keyword = 25\n",
        "\n",
        "Operation = Test_Keyword #@param [\"None\", \"CreatePosting\", \"Test_Keyword\"] {type: \"raw\"}\n",
        "Source = posts   #@param {type: \"raw\"}\n",
        "\n",
        "Start_Date = \"\" #@param {type: \"string\"}\n",
        "RTL = False     #@param {type: \"boolean\"}\n",
        "Insert_Keyword = False     #@param {type: \"boolean\"}\n",
        "\n",
        "Keyword = \"\" #@param {type: \"string\"}\n",
        "URL = \"\"    #@param {type: \"string\"}\n",
        "\n",
        "posts: list\n",
        "posting: list\n",
        "\n",
        "def createposting(posts, startdate, keyword= \"\", url= \"\", insertkeyword= False, rtl = False):\n",
        "    date = datetime.strptime(startdate, \"%Y-%m-%d\")\n",
        "    posting = []\n",
        "    for i in range(len(posts)):\n",
        "        dategmt = date - timedelta(hours = 3)\n",
        "        content = posts[i]['content']\n",
        "\n",
        "        if keyword and url:\n",
        "            if insertkeyword and content.find(keyword) == -1:\n",
        "                content = content + f\"\\n<a href='{url}'>{keyword}</a>\"\n",
        "            else:\n",
        "                filling = f\"<a href='{url}'>{keyword}</a>\"\n",
        "                content = content.replace(keyword, filling)\n",
        "\n",
        "        if rtl:\n",
        "            content = f\"<div dir='rtl' style='direction: rtl;'>{content}</div>\"\n",
        "        posting.append({\n",
        "            'title':    posts[i]['title'],\n",
        "            'content':  content,\n",
        "            'date':     date.isoformat(),\n",
        "            'dategmt':  dategmt.isoformat()\n",
        "        })\n",
        "        date = date + timedelta(days= 1)\n",
        "    return posting\n",
        "\n",
        "def testkeyword(posts, keyword):\n",
        "    print(f\"Testing keyword \\\"{keyword}\\\" existence in post content. Post count: {len(posts)}\")\n",
        "    count = i = 0\n",
        "    for item in posts:\n",
        "        if item[\"content\"].find(keyword) == -1:\n",
        "            print(f\"Post {i} doesn't include the keyword in the content. Title: \\\"{item['title']}\\\".\")\n",
        "            count += 1\n",
        "        i += 1\n",
        "    print(f'Testing is complete. {f\"{count} posts\" if count > 0 else \"No posts\"} found dont include the keyword: \\'{keyword}\\'')\n",
        "\n",
        "if Operation == CreatePosting:\n",
        "    posting = createposting(Source, Start_Date, keyword= Keyword, url= URL, insertkeyword= Insert_Keyword, rtl= RTL)\n",
        "\n",
        "elif Operation == Test_Keyword:\n",
        "    testkeyword(Source, Keyword)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rABmagkdcIG2"
      },
      "outputs": [],
      "source": [
        "#@title  { form-width: \"2%\" }\n",
        "#@markdown #### Test posting\n",
        "\n",
        "Post_Index = 1 #@param {type: \"number\"}\n",
        "\n",
        "posting[Post_Index]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Zou7B-2F5Okm"
      },
      "source": [
        "####  WP API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wkFvDADU5Okm"
      },
      "outputs": [],
      "source": [
        "#@title  { form-width: \"2%\" }\n",
        "#@markdown #### Site/User/Pass are space separated lists\n",
        "\n",
        "import requests \n",
        "from requests.auth import HTTPBasicAuth\n",
        "\n",
        "get = requests.get\n",
        "post = requests.post\n",
        "\n",
        "BulkPost = 1\n",
        "\n",
        "Operation = None #@param [\"BulkPost\", 'None'] {type: \"raw\"}\n",
        "\n",
        "Websites = 'https://beuta.com.ru' #@param {type: \"string\"}\n",
        "Users = '' #@param {type: \"string\"}\n",
        "Passwords = '' #@param {type: \"string\"}\n",
        "Data_Source = posting #@param {type:'raw'}\n",
        "\n",
        "media_end = '/wp-json/wp/v2/media'\n",
        "posts_end = '/wp-json/wp/v2/posts'\n",
        "\n",
        "if not 'json_obj'in globals():\n",
        "    json_obj = ''\n",
        "    obj = ''\n",
        "\n",
        "def wp_bulk_post(urlstring, usernames, passwords, datasource):\n",
        "    urls = tuple(map( lambda str: str.strip(), urlstring.split(' ')))\n",
        "    users = tuple(map( lambda str: str.strip(), usernames.split(' ')))\n",
        "    passes = tuple(map( lambda str: str.strip(), passwords.split(' ')))\n",
        "\n",
        "    if not (len(urls) == len(users) == len(passes)):\n",
        "        print(f\"Error. Site-User-Password list doesn't match.\\n Sites: {urls}  Usernames: {users}  Password: {passes}\")\n",
        "        return\n",
        "\n",
        "    posted_urls = []\n",
        "    params = \"&_fields=author,id,featured_media\"\n",
        "    i = 0\n",
        "    for obj in datasource:\n",
        "        url = urls[i] + posts_end\n",
        "        username = users[i]\n",
        "        password = passes[i]\n",
        "\n",
        "        post_title = obj['title'] if 'title' in obj else ''\n",
        "        post_slug = slugfy(post_title)\n",
        "        post_content = obj['content'] if 'content' in obj else ''\n",
        "        post_status = obj['status'] if 'status' in obj else 'publish'\n",
        "\n",
        "        post_date = obj['date'] if 'date' in obj else False\n",
        "        post_date_gmt = obj['dategmt'] if 'dategmt' in obj else False\n",
        "        post_categories = obj['categories'] if 'categories' in obj else False\n",
        "        post_image = obj['img_id'] if 'img_id' in obj else False\n",
        "\n",
        "        data = {\n",
        "            'format':   'standard',\n",
        "            'ping_status':'open',\n",
        "            'status':   post_status,\n",
        "            'title':    post_title,\n",
        "            'slug':     post_slug,\n",
        "            'content':  post_content\n",
        "        }\n",
        "\n",
        "        if post_date:\n",
        "            data['date'] = post_date\n",
        "\n",
        "        if post_date_gmt:\n",
        "            data['date_gmt'] = post_date_gmt\n",
        "\n",
        "        if post_categories:\n",
        "            data['categories'] = post_categories\n",
        "\n",
        "        if post_image:\n",
        "            data['featured_media'] = post_image\n",
        "\n",
        "        res = post(url, auth = HTTPBasicAuth(username, password), data = data)\n",
        "        if res:\n",
        "            print(res.status_code, \"Success\" if res.status_code == 201 else \"Fail\")\n",
        "            if res.status_code == 201:\n",
        "                posted_urls.append(res.json()['guid']['rendered'])\n",
        "\n",
        "        else:\n",
        "            print(\"Error. Response is empty.\")\n",
        "        i += 1\n",
        "        if i == len(urls):\n",
        "            i = 0\n",
        "    return posted_urls\n",
        "\n",
        "def slugfy(str):\n",
        "    return str.lower().strip().replace(' ','-')\n",
        "\n",
        "if Operation == BulkPost:\n",
        "    posted_urls = wp_bulk_post(Websites, Users, Passwords, Data_Source)\n",
        "    if posted_urls:\n",
        "        for i in posted_urls:\n",
        "            print(i)  "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JxyTBvSdq6-t"
      },
      "source": [
        "#### XML File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lT83XDhQedZT"
      },
      "outputs": [],
      "source": [
        "#@title  { form-width: \"2%\" }\n",
        "#@markdown\n",
        "\n",
        "#Edit prices \"round((x + x*0.65)/18.6, 2)\"\n",
        "#Edit currency \"'USD'\"\n",
        "\n",
        "Callback = 10\n",
        "Edit = 20\n",
        "View = 30\n",
        "\n",
        "Operation = Edit #@param {type: \"raw\"} [\"Callback\",\"Edit\", \"View\"]\n",
        "File = \"/content/yenitoptanci1.xml\" #@param {type: \"string\"}\n",
        "Element = \"IndirimliFiyat\" #@param {type: \"string\"}\n",
        "Input = None #@param {type: \"raw\"}\n",
        "Attr = \"\" #@param {type: \"string\"}\n",
        "Numbers = True #@param {type:'boolean'}\n",
        "\n",
        "if File and Element:\n",
        "    if Operation == Callback:\n",
        "        data = xmlcall(File, Element, Input)\n",
        "\n",
        "    elif Operation == Edit:\n",
        "        xmledit(File, Element, value = Input, numbers = Numbers)\n",
        "\n",
        "    elif Operation == View:\n",
        "        stuff = xmlview(File, Element, attr = Attr)    \n",
        "    \n",
        "#with prop b_name = xml_data.find('child', {'name':'Frank'}) prop_value = b_name.get('test')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0Lt2P-S-rOU-"
      },
      "source": [
        "#### XML Products Adjestments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BSfOH-SeS1eE"
      },
      "outputs": [],
      "source": [
        "#@title  { form-width: \"2%\" }\n",
        "#@markdown\n",
        "\n",
        "ViewPriceAndCurrency = 0\n",
        "EditPriceAndCurrency = 10\n",
        "FixMissingSKU = 20\n",
        "\n",
        "Operation = ViewPriceAndCurrency #@param {type: \"raw\"} [\"ViewPriceAndCurrency\",\"EditPriceAndCurrency\", \"FixMissingSKU\"]\n",
        "File = \"\" #@param {type: \"string\"}\n",
        "PriceNode = \"\" #@param {type: \"string\"}\n",
        "SalePriceNode = \"\" #@param {type: \"string\"}\n",
        "CurrencyNode = \"\" \n",
        "CurrencyUnit = \"\" #@param {type: \"string\"}\n",
        "CurrencyRate = \"0.053\" #@param {type: \"string\"}\n",
        "PriceChange = \"+65%\" #@param {type: \"string\"}\n",
        "\n",
        "SKUNode = \"\" #@param {type: \"string\"}\n",
        "ParentSKUNode = \"\" #@param {type: \"string\"}\n",
        "\n",
        "def wcpropertyview(filepath,\n",
        "              pricenode = \"\",\n",
        "              salepricenode = \"\", \n",
        "              currencynode = \"\"):\n",
        "    if pricenode:\n",
        "        xmledit(filepath, pricenode, value = \"\", numbers = True)\n",
        "\n",
        "    if salepricenode:\n",
        "        xmledit(filepath, salepricenode, value = \"\", numbers = True)\n",
        "\n",
        "    if currencynode:\n",
        "        xmledit(filepath, currencynode, value = \"\", numbers = False)\n",
        "    return\n",
        "\n",
        "def wcpricesandcurr(filepath,\n",
        "            pricenode = \"\",\n",
        "            salepricenode = \"\", \n",
        "            currnode = \"\",\n",
        "            pricechange = \"\",\n",
        "            currunit = \"\",\n",
        "            currrate = \"\"):\n",
        "\n",
        "    priceupdateoperation = ''\n",
        "    dopriceupdate = pricechange or currrate\n",
        "    docurrcodeupdate = currnode and currunit\n",
        "    if dopriceupdate:\n",
        "        pricechange = pricechange.strip()\n",
        "        if (pricenode and pricechange) or currrate:\n",
        "            if pricechange[0] != '+' and pricechange[0] != '-':\n",
        "                raise Exception(\"In order to complete price update the price change must be preceeded with a sign.\")\n",
        "                \n",
        "            sign = pricechange[0]\n",
        "            pricechange = pricechange[1:]\n",
        "            amount = f\"x*{float(pricechange.replace('%',''))/100}\" if '%' in pricechange else pricechange\n",
        "            priceupdate = sign + amount if amount else \"\"\n",
        "            priceupdate = f\"x {priceupdate}\" if not currrate else f\"(x {priceupdate})*{currrate}\"\n",
        "            print(f\"{'Requested price change:':>18} {priceupdate}\")\n",
        "            priceupdateoperation = f\"round(({priceupdate}), 2)\"\n",
        "\n",
        "    if docurrcodeupdate:\n",
        "        print(f\"{'Currency code updated:':>18} {currunit}\")\n",
        "\n",
        "    newfilenamesuffix = f\" {sign + pricechange if pricechange else ''}{' x' + currrate if currrate else ''}{' ' + currunit if currunit else ''}\"\n",
        "    splittedfilename = os.path.splitext(filepath)\n",
        "    newfilename = splittedfilename[0] + newfilenamesuffix + splittedfilename[1]\n",
        "\n",
        "    newsavedfilename = \"\"\n",
        "    if priceupdateoperation:\n",
        "        if pricenode:\n",
        "            print(f\"Updating price values. Price property xml node name: {pricenode}\")\n",
        "            xmledit(filepath, pricenode, value = priceupdateoperation, numbers = True, savefile = newfilename)\n",
        "            newsavedfilename = newfilename\n",
        "\n",
        "        filepath = newsavedfilename if newsavedfilename else filepath\n",
        "        if salepricenode:\n",
        "            print(f\"Updating sale price values. Sale price property xml node name: {salepricenode}\")\n",
        "            xmledit(filepath, salepricenode, value = priceupdateoperation, numbers = True, savefile = newfilename)\n",
        "            newsavedfilename = newfilename  \n",
        "\n",
        "    filepath = newsavedfilename if newsavedfilename else filepath\n",
        "\n",
        "    if docurrcodeupdate:\n",
        "        xmledit(filepath, currnode, value = f\"'{currunit}'\", numbers = False, savefile = newfilename)          \n",
        "    \n",
        "def fixmissingSku():\n",
        "  return\n",
        " \n",
        "if File:\n",
        "    if Operation == ViewPriceAndCurrency:\n",
        "        wcpropertyview(File,\n",
        "                pricenode = PriceNode,\n",
        "                salepricenode = SalePriceNode, \n",
        "                currencynode = CurrencyNode)\n",
        "\n",
        "    elif Operation == EditPriceAndCurrency:\n",
        "        wcpricesandcurr(File,\n",
        "                  PriceNode,\n",
        "                  SalePriceNode,\n",
        "                  currnode = CurrencyNode,\n",
        "                  pricechange = PriceChange, \n",
        "                  currunit = CurrencyUnit,\n",
        "                  currrate = CurrencyRate)\n",
        "\n",
        "    elif Operation == FixMissingSKU:\n",
        "        fixmissingSku\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf_yNqx_rSiu"
      },
      "source": [
        "#### XML to CSV WC Products Mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "23d-FGI4OglQ"
      },
      "outputs": [],
      "source": [
        "#@title  { form-width: \"50px\" }\n",
        "\n",
        "Map = 20\n",
        "SaveMap = 10\n",
        "LoadandMap = 21\n",
        "LoadandView = 22\n",
        "WoocommerceItemTesting = 111\n",
        "\n",
        "Unset = None\n",
        "Nested = 'Nested'\n",
        "ParentSKU = 'ParentSKU'\n",
        "SharedSKU = 'SharedSKU'\n",
        "\n",
        "UsePropertyList = 'UsePropertyList'\n",
        "UseAttributeTagProperties = 'UseAttributeTagProperties'\n",
        "\n",
        "wocommerce_header = [ 'ID', 'Type', 'SKU', 'Name', 'Published', 'Is featured?', 'Visibility in catalog', 'Short description', 'Description', 'Date sale price starts', 'Date sale price ends', 'Tax status', 'Tax class', 'In stock?', 'Stock', 'Backorders allowed?', 'Sold individually?', 'Weight (kg)', 'Length (cm)', 'Width (cm)', 'Height (cm)', 'Allow customer reviews?', 'Purchase note', 'Sale price', 'Regular price', 'Categories', 'Tags', 'Shipping class', 'Images', 'Download limit', 'Download expiry days', 'Parent', 'Grouped products', 'Upsells', 'Cross-sells', 'External URL', 'Button text', 'Position', 'Attribute 1 name', 'Attribute 1 value(s)', 'Attribute 1 visible', 'Attribute 1 global', 'Attribute 2 name', 'Attribute 2 value(s)', 'Attribute 2 visible', 'Attribute 2 global', 'Meta: _wpcom_is_markdown', 'Download 1 name', 'Download 1 URL', 'Download 2 name', 'Download 2 URL']\n",
        "defaultvalues = {\"ID\":  \"\", \"Type\":  \"\", \"SKU\":  \"\", \"Name\":  \"\", \"Published\":  \"1\", \"Is featured?\":  \"0\", \"Visibility in catalog\":  \"visible\", \"Short description\":  \"\", \"Description\":  \"\", \"Date sale price starts\":  \"\", \"Date sale price ends\":  \"\", \"Tax status\":  \"taxable\", \"Tax class\":  \"\", \"In stock?\":  \"1\", \"Stock\":  \"\", \"Backorders allowed?\":  \"0\", \"Sold individually?\":  \"0\", \"Weight (kg)\":  \"\", \"Length (cm)\":  \"\", \"Width (cm)\":  \"\", \"Height (cm)\":  \"\", \"Allow customer reviews?\":  \"1\", \"Purchase note\":  \"\", \"Sale price\":  \"\", \"Regular price\":  \"\", \"Categories\":  \"\", \"Tags\":  \"\", \"Shipping class\":  \"class10\", \"Images\":  \"\", \"Download limit\":  \"\", \"Download expiry days\":  \"\", \"Parent\":  \"\", \"Grouped products\":  \"\", \"Upsells\":  \"\", \"Cross-sells\":  \"\", \"External URL\":  \"\", \"Button text\":  \"\", \"Position\":  \"0\", \"Download 1 name\":  \"\", \"Download 1 URL\":  \"\", \"Download 2 name\":  \"\", \"Download 2 URL\":  \"\"}\n",
        "defaultmappingoptions = { 'MapSimpleProducts': True, 'MapVariableProducts': True, 'VariationStructure': Nested, 'CategorySeparator': ' -> ', 'AttributeCollectingMethod': UseAttributeTagProperties}\n",
        "defaultproductnode = 'product'\n",
        "\n",
        "Operation = SaveMap #@param [\"Map\",\"SaveMap\", \"LoadandMap\",\"LoadandView\", \"WoocommerceItemTesting\"] {type:\"raw\"}\n",
        "MapFile = \"\" #@param {type:'string'}\n",
        "XMLFile = \"\"   #@param {type:'string'}\n",
        "\n",
        "#@markdown <br> &nbsp;&nbsp;&nbsp; Mapping Options. Overrides loaded options.\n",
        "\n",
        "MapSimpleProducts = Unset #@param [\"True\",\"False\", \"Unset\"] {type:\"raw\"}\n",
        "MapVariableProducts = Unset #@param [\"True\",\"False\", \"Unset\"] {type:\"raw\"}\n",
        "VariationStructure = ParentSKU #@param [\"Variation\", \"ParentSKU\", \"SharedSKU\", \"Unset\"] {type:\"raw\"}\n",
        "CategorySeparator = \"\" #@param {type:'string'}\n",
        "AttributeCollectingMethod = Unset #@param [\"UsePropertyList\", \"UseAttributeTagProperties\", \"Unset\"] {type:\"raw\"}\n",
        "\n",
        "mappingoptions = {}\n",
        "mappingoptions['MapSimpleProducts'] = MapSimpleProducts  \n",
        "mappingoptions['MapVariableProducts'] = MapVariableProducts \n",
        "mappingoptions['VariationStructure'] = VariationStructure \n",
        "mappingoptions['CategorySeparator'] = CategorySeparator  \n",
        "mappingoptions['AttributeCollectingMethod'] = AttributeCollectingMethod  \n",
        "\n",
        "#@markdown <br> &nbsp;&nbsp;&nbsp; Mapping Parameters. Enumerated elements: element-d{n}\n",
        "ProductNode = \"\" #@param {type:'string'}\n",
        "if Operation == Map or Operation == SaveMap:\n",
        "    Type = \"\" #@param {type:'string'}\n",
        "    ProductId  = \"\" #@param {type:'string'} \n",
        "    SKU = \"\" #@param {type:'string'} \n",
        "    Name = \"\" #@param {type:'string'} \n",
        "    Featured = \"\" #@param {type:'string'}\n",
        "    Visible = \"\" #@param {type:'string'} \n",
        "    ShortDescription = \"\" #@param {type:'string'}\n",
        "    Description = \"\" #@param {type:'string'}\n",
        "    Stock = \"\" #@param {type:'string'} \n",
        "    Weight = \"\" #@param {type:'string'} \n",
        "    Length = \"\" #@param {type:'string'} \n",
        "    Width = \"\" #@param {type:'string'} \n",
        "    Height = \"\" #@param {type:'string'} \n",
        "    Note = \"\" #@param {type:'string'} \n",
        "    SalePrice = \"\" #@param {type:'string'} \n",
        "    RegularPrice = \"\" #@param {type:'string'} \n",
        "    Category = \"\" #@param {type:'string'}\n",
        "    Tags = \"\" #@param {type:'string'}\n",
        "    ShippingClass = \"\" #@param {type:'string'}\n",
        "    FeaturedImage = \"\" #@param {type:'string'} \n",
        "    Images = \"\" #@param {type:'string'} \n",
        "    Option = \"\" #@param {type:'string'}\n",
        "    ParentSKU = \"\" #@param {type:'string'}\n",
        "    AttributeList = \"\" #@param {type:'string'}\n",
        "    Attribute = \"\" #@param {type:'string'} \n",
        "    AttributeName = \"\" #@param {type:'string'} \n",
        "    AttributeValue = \"\" #@param {type:'string'} \n",
        "    AttributeVisible = \"\" #@param {type:'string'}\n",
        "\n",
        "    mapping = {}\n",
        "    mapping[\"MappingOptions\"] = mappingoptions\n",
        "    mapping['ProductNode']= ProductNode if ProductNode else defaultproductnode\n",
        "    mapping[\"Type\"]  = Type\n",
        "    mapping[\"Id\"]  = ProductId                      \n",
        "    mapping[\"SKU\"] = SKU                               \n",
        "    mapping[\"Name\"] = Name                                \n",
        "    mapping[\"Featured\"] = Featured                                  \n",
        "    mapping[\"Visible\"] = Visible                                   \n",
        "    mapping[\"ShortDescription\"] = ShortDescription                    \n",
        "    mapping[\"Description\"] = Description                      \n",
        "    mapping[\"Stock\"] = Stock                             \n",
        "    mapping[\"Weight\"] = Weight                              \n",
        "    mapping[\"Length\"] = Length                                   \n",
        "    mapping[\"Width\"] = Width                                  \n",
        "    mapping[\"Height\"] = Height                                     \n",
        "    mapping[\"Note\"] = Note                            \n",
        "    mapping[\"SalePrice\"] = SalePrice                 \n",
        "    mapping[\"RegularPrice\"] = RegularPrice                   \n",
        "    mapping[\"Category\"] = Category                       \n",
        "    mapping[\"Tags\"] = Tags                                \n",
        "    mapping[\"ShippingClass\"] = ShippingClass                            \n",
        "    mapping[\"Images\"] = Images   \n",
        "    mapping[\"FeaturedImage\"] = FeaturedImage \n",
        "\n",
        "    mapping[\"Option\"] = Option\n",
        "    mapping[\"ParentSKU\"] = ParentSKU\n",
        "    mapping[\"AttributeList\"] = AttributeList                        \n",
        "    mapping[\"Attribute\"] = Attribute                           \n",
        "    mapping[\"AttributeName\"] = AttributeName                      \n",
        "    mapping[\"AttributeValue\"] = AttributeValue                        \n",
        "    mapping[\"AttributeVisible\"] = AttributeVisible                    \n",
        "\n",
        "def wcsavemap(mapping: dict, filepath = \"\"):\n",
        "    mappingoptions = mapping['MappingOptions']\n",
        "    if not mappingoptions['MapSimpleProducts']: mappingoptions['MapSimpleProducts'] = defaultmappingoptions['MapSimpleProducts']\n",
        "    if not mappingoptions['MapVariableProducts']: mappingoptions['MapVariableProducts'] = defaultmappingoptions['MapVariableProducts']\n",
        "    if not mappingoptions['VariationStructure']: mappingoptions['VariationStructure'] = defaultmappingoptions['VariationStructure']\n",
        "    if not mappingoptions['CategorySeparator']: mappingoptions['CategorySeparator'] = defaultmappingoptions['CategorySeparator']\n",
        "    if not mappingoptions['AttributeCollectingMethod']: mappingoptions['AttributeCollectingMethod'] = defaultmappingoptions['AttributeCollectingMethod']\n",
        "\n",
        "    if  not filepath:\n",
        "        filepath = \"wc-xml-mapping.json\"\n",
        "        overwrite = False\n",
        "    else:\n",
        "        overwrite = True\n",
        "    if   mapping:\n",
        "        if 'write_json' in globals():\n",
        "            write_json(mapping, filepath, overwrite)                      #getattrs(mapping, True)\n",
        "        else:\n",
        "            print(\"write_json is undefined.\")\n",
        "    else:\n",
        "        print(\"Mapping is undefined.\")\n",
        "\n",
        "def wcloadmap(mapjson, xmlfile = None, defaultvalues = None, mappingoptionsoverride = None):\n",
        "    mappings = read_json(mapjson)\n",
        "    if not mappings:\n",
        "        print(\"wcloadmap error. the options json file wasn't read.\")\n",
        "        return\n",
        "\n",
        "    if xmlfile and defaultvalues:\n",
        "        if mappingoptionsoverride:\n",
        "            for key in mappingoptionsoverride:\n",
        "                optionval0 = mappingoptionsoverride[key]\n",
        "                if optionval0:\n",
        "                    mappings['MappingOptions'][key] = optionval0\n",
        "        return wcmapxml(xmlfile, mappings, defaultvalues)\n",
        "    else:\n",
        "        options = mappings['MappingOptions']\n",
        "        print('Mapping options:')\n",
        "        for mappingoptionkey in options:\n",
        "            print(f' {mappingoptionkey}: {options[mappingoptionkey]}')\n",
        "        print(\"\\nProperty mappings:\")\n",
        "        for mappingkey in mappings:\n",
        "            if mappingkey == 'MappingOptions':\n",
        "                continue\n",
        "            else:\n",
        "                print(f\" {mappingkey}: '{mappings[mappingkey]}'\")\n",
        "\n",
        "def wccats(values, separator):\n",
        "    valuelist = values.split(separator)\n",
        "    if valuelist:\n",
        "        return createcommalist(valuelist, sep = ' > ')\n",
        "\n",
        "def wcmapwithsharedsku(products, keymap: dict, defaultvalues: dict):\n",
        "    if not keymap:\n",
        "        print(\"Keymap is undefined or empty\")\n",
        "        return\n",
        "    if not products:\n",
        "        print(\"Items is undefined or empty\")\n",
        "        return\n",
        "\n",
        "def finditem(somelist: list, comparingmethod, deleteiffound = False):\n",
        "    for index in range(len(somelist)):\n",
        "        if comparingmethod(somelist[index]):\n",
        "            if deleteiffound:\n",
        "                return somelist.pop(index)\n",
        "            else:\n",
        "                return somelist[index]\n",
        "    return None\n",
        "\n",
        "def wcmapproductinfo(product, keymap: dict, defaultvalues: dict):\n",
        "    mappingoptions = keymap[\"MappingOptions\"]\n",
        "    separator = mappingoptions[\"CategorySeparator\"]\n",
        "    useattributetagproperties = mappingoptions[\"AttributeCollectingMethod\"] == UseAttributeTagProperties\n",
        "    productmapping = defaultvalues.copy()\n",
        "\n",
        "    #main info.\n",
        "    productsku = product.find(keymap[\"SKU\"]).text\n",
        "    productname = product.find(keymap[\"Name\"]).text\n",
        "    producttype = product.product_type if product.product_type != None else 'simple'\n",
        "\n",
        "    if product.product_parentsku != None:\n",
        "        productmapping[\"Parent\"] = product.product_parentsku\n",
        "    productmapping[\"Name\"] = productname\n",
        "    productmapping[\"Type\"] = producttype\n",
        "\n",
        "    productmapping[\"Description\"] = product.find(keymap[\"Description\"]).text\n",
        "    productmapping[\"Short description\"] = propertyvalue(product.find(keymap[\"ShortDescription\"])) if keymap[\"ShortDescription\"] else \"\"\n",
        "\n",
        "    imgitems = product.find_all(keymap[\"Images\"])\n",
        "    imglist = list(map(propertyvalue, imgitems))\n",
        "    if keymap[\"FeaturedImage\"]:\n",
        "        featuredimage = product.find(keymap[\"FeaturedImage\"]).text\n",
        "        if featuredimage and not featuredimage in imglist:\n",
        "            imglist.insert(0, featuredimage)\n",
        "    productmapping[\"Images\"]  = createcommalist(imglist)\n",
        "\n",
        "    productmapping[\"SKU\"] = productsku\n",
        "    productmapping[\"Regular price\"] = product.find(keymap[\"RegularPrice\"]).text\n",
        "    productmapping[\"Sale price\"] = propertyvalue(product.find(keymap[\"SalePrice\"])) if keymap[\"SalePrice\"] else \"\"\n",
        "\n",
        "    #For simple and variable products. category tree and tags.\n",
        "    if producttype == 'simple' or producttype == 'variable':\n",
        "        cats= product.find(keymap[\"Category\"]).text\n",
        "        if separator.strip() != '>':\n",
        "            cats = wccats(cats, separator)\n",
        "        productmapping['Categories'] = cats\n",
        "        if keymap[\"Tags\"]: productmapping[\"Tags\"] = propertyvalue(product.find(keymap[\"Tags\"]))\n",
        "\n",
        "    #stock.\n",
        "    if keymap[\"Stock\"]:\n",
        "        stock = propertyvalue(product.find(keymap[\"Stock\"]))\n",
        "        productmapping[\"Stock\"] = stock\n",
        "        productmapping[\"In stock?\"] = \"0\" if stock == \"0\" or stock == \"\" else \"1\"\n",
        "    else:\n",
        "        productmapping[\"In stock?\"] = \"1\"\n",
        "\n",
        "    #other information.\n",
        "    if producttype == 'variation':\n",
        "        product[f\"Is featured?\"] = \"0\"\n",
        "    if keymap[\"Height\"]: productmapping[\"Height (cm)\"] = propertyvalue(product.find(keymap[\"Height\"]))           \n",
        "    if keymap[\"Width\"]: productmapping[\"Width (cm)\"] = propertyvalue(product.find(keymap[\"Width\"])) \n",
        "    if keymap[\"Length\"]: productmapping[\"Length (cm)\"] = propertyvalue(product.find(keymap[\"Length\"])) \n",
        "    if keymap[\"Weight\"]: productmapping[\"Weight (kg)\"] = propertyvalue(product.find(keymap[\"Weight\"]))\n",
        "    if keymap[\"ShippingClass\"]: productmapping[\"Shipping class\"] = propertyvalue(product.find(keymap[\"ShippingClass\"]))\n",
        "\n",
        "    #Set the parent product attributes and their values from variations\n",
        "    if product.product_attributes == None:\n",
        "        if producttype == 'variable':\n",
        "            product.product_attributes = product.parent_attributes\n",
        "        else:\n",
        "            product.product_attributes = parsecommalist(keymap[\"AttributeList\"]) if not useattributetagproperties else product.find_all(keymap[\"Attribute\"])\n",
        "\n",
        "    attrstr = \"\"\n",
        "    if product.product_attributes:\n",
        "        j = 1\n",
        "        for attr in product.product_attributes:\n",
        "            if producttype == 'variable':\n",
        "                attrname = attr\n",
        "                attrval = createcommalist(product.product_attributes[attr], spaced= False)\n",
        "            elif useattributetagproperties:\n",
        "                attrname = attr.get(keymap[\"AttributeName\"])\n",
        "                attrval = attr.get(keymap[\"AttributeValue\"])\n",
        "            else:\n",
        "                attrname = attr\n",
        "                attrval = product.find(attr).text\n",
        "\n",
        "            if attrname and attrval:\n",
        "                attrstr += f'{attrname} [{attrval.replace(\",\", \", \")}] '\n",
        "                productmapping[f\"Attribute {j} name\"] = attrname\n",
        "                productmapping[f\"Attribute {j} value(s)\"] = attrval\n",
        "                productmapping[f\"Attribute {j} global\"] = \"1\"\n",
        "\n",
        "                if producttype == 'variable':\n",
        "                    productmapping[f\"Attribute {j} visible\"] = \"1\"\n",
        "\n",
        "                elif product.product_parent:\n",
        "                    if not attrname in product.product_parent.parent_attributes:\n",
        "                        product.product_parent.parent_attributes[attrname] = set()\n",
        "                    product.product_parent.parent_attributes[attrname].add(attrval)\n",
        "                j += 1\n",
        "  \n",
        "    attrstr = \"Attributes: \" + attrstr if attrstr else \"\"\n",
        "    print(f\"Product mapped:  ->  Type: {producttype.capitalize().ljust(10)} SKU: {productsku.ljust(25)} Name: {productname.ljust(75)} {attrstr}\") \n",
        "    return productmapping\n",
        "\n",
        "def wcmapwithparentsku(products, keymap: dict, defaultvalues: dict):\n",
        "    if not keymap:\n",
        "        print(\"Keymap is undefined or empty\")\n",
        "        return\n",
        "    if not products:\n",
        "        print(\"Items is undefined or empty\")\n",
        "        return\n",
        "\n",
        "    export = []\n",
        "    mappingoptions = keymap[\"MappingOptions\"]\n",
        "    mapvariables = mappingoptions[\"MapVariableProducts\"]\n",
        "    mapsimples = mappingoptions[\"MapSimpleProducts\"]\n",
        "    useattributetagproperties = mappingoptions[\"AttributeCollectingMethod\"] == UseAttributeTagProperties\n",
        "    simplesandvariables = products.copy()\n",
        "\n",
        "    mapcount = 0\n",
        "    i = 0\n",
        "    for product in products:\n",
        "        if mapvariables and not keymap[\"ParentSKU\"]:\n",
        "            print(\"Mapping doesn't have required ParentSKU key.\")\n",
        "            return\n",
        "        possibleparentsku = product.find(keymap[\"ParentSKU\"]).text\n",
        "        productsku = product.find(keymap[\"SKU\"]).text\n",
        "        if possibleparentsku and possibleparentsku != productsku:\n",
        "            #finding nemo.\n",
        "            getparentmethod = lambda possibleparent: possibleparent.find(keymap['SKU']).text == possibleparentsku\n",
        "            parent = finditem(simplesandvariables, getparentmethod, deleteiffound= False)\n",
        "            if parent:\n",
        "                if not useattributetagproperties:\n",
        "                    product_attributes = parsecommalist(keymap[\"AttributeList\"])\n",
        "                else:\n",
        "                    product_attributes = product.find_all(keymap[\"Attribute\"])\n",
        "                if not product_attributes:\n",
        "                    print(f'wcmapwithparentsku error: can not fetch attribute properties from the key mappings.\\nVariations will be mapped as simple products\\nAttributeList {keymap[\"AttributeList\"]} Attribute {keymap[\"Attribute\"]}')\n",
        "                    continue\n",
        "                  \n",
        "                parent.product_type = 'variable'\n",
        "                if parent.parent_attributes == None:\n",
        "                    parent.parent_attributes = {}\n",
        "\n",
        "                product.product_type = 'variation'\n",
        "                product.product_parent = parent\n",
        "                product.product_parentsku = possibleparentsku\n",
        "                product.product_attributes = product_attributes\n",
        "\n",
        "                singlevariation = wcmapproductinfo(product, keymap, defaultvalues)\n",
        "\n",
        "                export.append(singlevariation)\n",
        "                mapcount += 1\n",
        "\n",
        "                #remove variation from simpleandvaiable list.\n",
        "                simplesandvariables.remove(product)\n",
        "        i += 1\n",
        "\n",
        "    for product in simplesandvariables:\n",
        "        issimple = product.product_type != 'variable'\n",
        "        domap = (not issimple and mapvariables) or (issimple and mapsimples)\n",
        "        if domap:\n",
        "            productmapping = wcmapproductinfo(product, keymap, defaultvalues)\n",
        "            export.append(productmapping)\n",
        "            mapcount += 1\n",
        "\n",
        "    print(f\"Total mappings: {mapcount}\")\n",
        "\n",
        "    return export\n",
        "\n",
        "def wcmapnested(items, keymap: dict, defaultvalues: dict ):\n",
        "    if not keymap:\n",
        "        print(\"wcmapnested error: Keymap is undefined or empty\")\n",
        "        return\n",
        "    if not items:\n",
        "        print(\"wcmapnested error: wcmapnestedItems is undefined or empty\")\n",
        "        print(f\"Items type: {type(items)} Len:{len(items) if items != None else 'items is None.'}\\n\")\n",
        "        return\n",
        "\n",
        "    export = []\n",
        "    mappingoptions = keymap[\"MappingOptions\"]\n",
        "    mapvariables = mappingoptions[\"MapVariableProducts\"]\n",
        "    mapsimples = mappingoptions[\"MapSimpleProducts\"]\n",
        "\n",
        "    mapcount = 0\n",
        "    for item in items:\n",
        "        options = item.find_all(keymap[\"Option\"])\n",
        "        variable = len(options) > 1\n",
        "\n",
        "        #shared props between variable/simple/variation\n",
        "        name = item.find(keymap[\"Name\"]).text\n",
        "        desc = item.find(keymap[\"Description\"]).text\n",
        "        shortdesc = propertyvalue(item.find(keymap[\"ShortDescription\"])) if keymap[\"ShortDescription\"] else \"\"\n",
        "        catsraw = item.find(keymap[\"Category\"]).text\n",
        "        cats = wccats(catsraw, mappingoptions[\"CategorySeparator\"])\n",
        "        imgitems = item.find_all(keymap[\"Images\"])\n",
        "        imgs = list(map(propertyvalue, imgitems))\n",
        "        imgstr = createcommalist(imgs)\n",
        "\n",
        "        if variable and mapvariables:\n",
        "            parentproductsku = f\"{options[0].find(keymap['SKU']).text[:-1]}00\"\n",
        "            parentattrs = {}\n",
        "            parentproduct = defaultvalues.copy()\n",
        "            parentproduct[\"Type\"] = 'variable'\n",
        "            parentproduct[\"SKU\"] = parentproductsku  \n",
        "            parentproduct[\"Name\"] = name\n",
        "            parentproduct[\"Images\"] = imgstr\n",
        "            parentproduct[\"Description\"] = desc\n",
        "            parentproduct[\"Short description\"] = shortdesc\n",
        "            parentproduct['Categories'] = cats\n",
        "\n",
        "            if keymap[\"Tags\"]:\n",
        "                parentproduct[\"Tags\"] = propertyvalue(item.find(keymap[\"Tags\"]))\n",
        "\n",
        "            export.append(parentproduct)\n",
        "            mapcount += 1\n",
        "            print(f\"Variable:   ->  {parentproductsku}\\n\")\n",
        "\n",
        "        #add simple product or nested variations.\n",
        "        for option in options:\n",
        "            singlevariation = defaultvalues.copy()\n",
        "\n",
        "            #Set shared props for simple product/variation.\n",
        "            singlevariation[\"SKU\"] = option.find(keymap[\"SKU\"]).text\n",
        "            singlevariation[\"Regular price\"] = option.find(keymap[\"RegularPrice\"]).text\n",
        "            singlevariation[\"Sale price\"] = propertyvalue(option.find(keymap[\"SalePrice\"])) if keymap[\"SalePrice\"] else \"\"\n",
        "\n",
        "            if keymap[\"Stock\"]:\n",
        "                stock = propertyvalue(option.find(keymap[\"Stock\"]))\n",
        "                singlevariation[\"Stock\"] = stock\n",
        "                singlevariation[\"In stock?\"] = \"0\" if stock == \"0\" or stock == \"\" else \"1\"\n",
        "\n",
        "            if keymap[\"Height\"]:\n",
        "                singlevariation[\"Height (cm)\"] = propertyvalue(option.find(keymap[\"Height\"]))           \n",
        "\n",
        "            if keymap[\"Width\"]:\n",
        "                singlevariation[\"Width (cm)\"] = propertyvalue(option.find(keymap[\"Width\"])) \n",
        "\n",
        "            if keymap[\"Length\"]:\n",
        "                singlevariation[\"Length (cm)\"] = propertyvalue(option.find(keymap[\"Length\"])) \n",
        "\n",
        "            if keymap[\"Weight\"]:\n",
        "                singlevariation[\"Weight (kg)\"] = propertyvalue(option.find(keymap[\"Weight\"]))\n",
        "\n",
        "            if keymap[\"ShippingClass\"]:\n",
        "                singlevariation[\"Shipping class\"] = propertyvalue(option.find(keymap[\"ShippingClass\"]))\n",
        "\n",
        "            #if parent is variable add as a variation.  \n",
        "            if variable:\n",
        "                if mapvariables:\n",
        "                    singlevariation[\"Type\"] = 'variation'\n",
        "                    singlevariation[\"Parent\"] = parentproductsku\n",
        "\n",
        "                    attrset = option.find_all(keymap[\"Attribute\"])\n",
        "                    j = 1\n",
        "                    namevariation = \"\"\n",
        "                    for attr in attrset:\n",
        "                        attrname = attr.get(keymap[\"AttributeName\"])\n",
        "                        attrval = attr.get(keymap[\"AttributeValue\"])\n",
        "                        print(f\"Variation:  ->  attr: {attrname}  val: {attrval}\\n\")\n",
        "                        singlevariation[f\"Attribute {j} name\"] = attrname\n",
        "                        singlevariation[f\"Attribute {j} value(s)\"] = attrval\n",
        "                        singlevariation[f\"Attribute {j} global\"] = \"1\"\n",
        "                        singlevariation[f\"Is featured?\"] = \"0\"\n",
        "\n",
        "                        if not attrname in parentattrs:\n",
        "                            parentattrs[attrname] = set()          \n",
        "                        parentattrs[attrname].add(attrval)\n",
        "                        if j == 1:\n",
        "                            namevariation = attrval\n",
        "                        else:\n",
        "                            namevariation += f\" {attrval}\"\n",
        "                        j += 1\n",
        "                    singlevariation[\"Name\"] = f\"{name} {namevariation}\"\n",
        "\n",
        "            #add as simple product\n",
        "            elif mapsimples:\n",
        "                singlevariation[\"Type\"] = 'simple'\n",
        "                singlevariation[\"Images\"] = imgstr\n",
        "                singlevariation[\"Short description\"] = shortdesc\n",
        "\n",
        "                singlevariation[\"Name\"] = name\n",
        "                singlevariation['Categories'] = cats\n",
        "                singlevariation[\"Description\"] = desc\n",
        "\n",
        "                if keymap[\"Tags\"]:\n",
        "                    singlevariation[\"Tags\"] = propertyvalue(option.find(keymap[\"Tags\"]))\n",
        "\n",
        "            export.append(singlevariation)\n",
        "            mapcount += 1\n",
        "\n",
        "        #Set the parent product attributes and their values from variations\n",
        "        if variable:\n",
        "            if mapvariables:\n",
        "                i = 1\n",
        "                for attrkey in parentattrs:\n",
        "                    print(f\"Attribute Values:  {attrkey}  ->  {str(parentattrs[attrkey])}\\n\")\n",
        "                    parentproduct[f\"Attribute {i} name\"] = attrkey\n",
        "                    parentproduct[f\"Attribute {i} value(s)\"] = createcommalist(parentattrs[attrkey])\n",
        "                    parentproduct[f\"Attribute {i} visible\"] = \"1\"\n",
        "                    parentproduct[f\"Attribute {i} global\"] = \"1\"\n",
        "        elif mapsimples:\n",
        "            print(f\"Simple:   ->  {singlevariation['SKU']}\\n\")\n",
        "\n",
        "    print(f\"Total mappings: {mapcount}\")\n",
        "    return export\n",
        "\n",
        "def wcmapxml(xmlpath, mapping, defaultvalues):\n",
        "    if not mapping:\n",
        "        print(\"wcmapxml error: Keymap is undefined or empty.\")\n",
        "\n",
        "    try:\n",
        "        scrapenode = mapping[\"ProductNode\"]\n",
        "    except:\n",
        "        scrapenode = defaultproductnode\n",
        "\n",
        "    variationstructure = mapping[\"MappingOptions\"][\"VariationStructure\"]\n",
        "\n",
        "    if variationstructure == SharedSKU:\n",
        "        wcmapfunc = wcmapwithsharedsku\n",
        "\n",
        "    elif variationstructure == ParentSKU:\n",
        "        wcmapfunc = wcmapwithparentsku\n",
        "\n",
        "    elif variationstructure == Nested:\n",
        "        wcmapfunc = wcmapnested\n",
        "\n",
        "    else:\n",
        "        mapping[\"MappingOptions\"][\"MapVariableProducts\"] = False\n",
        "        wcmapfunc = wcmapnested\n",
        "\n",
        "    wcproc = lambda items: wcmapfunc(items, mapping, defaultvalues)\n",
        "\n",
        "    #@markdown <br> &nbsp;&nbsp;&nbsp; Mapped CSV file naming format.\n",
        "    csvoutput = f\"{exlessbase(xmlpath)}.csv\" #@param {type:\"string\"}\n",
        "    importjob = xmlcall(xmlpath, scrapenode, wcproc)\n",
        "    wcsv(wocommerce_header, importjob, csvoutput, quoting = csv.QUOTE_ALL)\n",
        "\n",
        "def wcitemtesting(items, mapfile= None, mappings= None):\n",
        "    print(f\"Woocommerce Item Testing\\nRecieved items count: {len(items)}\")\n",
        "    i = 0\n",
        "\n",
        "    for item in items:\n",
        "        print(items[i].product_type == None)\n",
        "        if i == 1:\n",
        "            item.product_type = \"Variable\"\n",
        "            item.product_attributes = {\"color\": set()}\n",
        "            item.product_attributes[\"color\"].add('yellow')\n",
        "        i += 1\n",
        "\n",
        "    items[1].product_attributes[\"color\"].add(\"red\")\n",
        "    if not 'size' in items[1].product_attributes:\n",
        "        items[1].product_attributes['size'] = set()\n",
        "        items[1].product_attributes['size'].add('XLLL')\n",
        "        items[1].product_attributes['size'].add('L')\n",
        "        items[1].product_attributes['size'].add('S')\n",
        "        items[1].product_attributes['size'].add('L')\n",
        "\n",
        "    if items[1].product_attributes:\n",
        "        print(items[1].product_attributes)\n",
        "    print(getattr(items[1], 'product_type', False))\n",
        "    print(items[1].product_type == None)\n",
        "\n",
        "if Operation == Map:\n",
        "    wcmapxml(XMLFile, mapping, defaultvalues)\n",
        "\n",
        "elif Operation == LoadandMap:\n",
        "    wcloadmap(MapFile, XMLFile, defaultvalues, mappingoptions)\n",
        "\n",
        "elif Operation == LoadandView:\n",
        "    wcloadmap(MapFile)\n",
        "\n",
        "elif Operation == SaveMap:\n",
        "    wcsavemap(mapping, MapFile)\n",
        "\n",
        "elif Operation == WoocommerceItemTesting:\n",
        "    xmlcall(XMLFile, ProductNode, wcitemtesting)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "H65KylwJrYi1"
      },
      "source": [
        "#### Products CVS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZqEu3vDTqnW2"
      },
      "outputs": [],
      "source": [
        "#@title  { form-width: \"2%\" }\n",
        "#@markdown\n",
        "\n",
        "Minimal = csv.QUOTE_MINIMAL\n",
        "All = csv.QUOTE_ALL\n",
        "NonNumeric = csv.QUOTE_NONNUMERIC\n",
        "_None = csv.QUOTE_NONE\n",
        "\n",
        "FileName = \"yenitoptanci7-3.csv\" #@param {type:\"string\"}\n",
        "Quoting = All # [\"Minimal\", \"All\", \"NonNumeric\", \"_None\"] {type:\"raw\"}\n",
        "\n",
        "wcsv(wocommerce_header, importjob, FileName, quoting = Quoting)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2w2MYPlGrbwx"
      },
      "source": [
        "#### MySQL Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IXpDEZh9edZU"
      },
      "outputs": [],
      "source": [
        "#@title  { form-width: \"2%\" }\n",
        "#@markdown\n",
        " \n",
        "# Thumbnail id from another language translated with Ligotek\n",
        "\n",
        "row = 'a:3:{s:8:\"lingotek\";a:4:{s:4:\"type\";s:4:\"post\";s:6:\"source\";i:3765;s:6:\"status\";s:7:\"current\";s:12:\"translations\";a:1:{s:5:\"en_US\";s:7:\"current\";}}s:2:\"ar\";i:3765;s:2:\"en\";i:4769;}'\n",
        "postid_re = r'(?<=\"ar\";i:)\\d+'\n",
        "query = \"SELECT description FROM emasri_ghiras_prod.qtstkjza6_term_taxonomy where `description` like '%lingotek%';\"\n",
        "\n",
        "def mysql_lingotek(conn: MySQLdb.Connection):\n",
        "    postid_re_ar = r'(?<=\"ar\";i:)\\d+'\n",
        "    postid_re_en = r'(?<=\"en\";i:)\\d+'\n",
        "    query = \"SELECT description FROM emasri_ghiras_prod.qtstkjza6_term_taxonomy where `description` like '%lingotek%';\"  \n",
        "    print(f\"Auto commit: {conn.get_autocommit()}\")\n",
        "    cur: MySQLdb.cursors.Cursor = conn.cursor()\n",
        "    cur.execute(query)\n",
        "    res = cur.fetchall()\n",
        "    if res:\n",
        "        for item in res:\n",
        "            item = item[0]\n",
        "            chk1 = re.search(postid_re_ar, item)\n",
        "            chk2 = re.search(postid_re_en, item)\n",
        "            if chk1 and chk2:\n",
        "                postar = chk1.group()\n",
        "                posten = chk1.group()\n",
        "                imgquery = f\"SELECT meta_value FROM emasri_ghiras_prod.qtstkjza6_postmeta where meta_key = '_thumbnail_id' and post_id = {postar};\"\n",
        "                cur.execute(imgquery)\n",
        "                res2 = cur.fetchone()\n",
        "                if res2:\n",
        "                    imgid = res2[0]\n",
        "                    query3 = f\"insert into `emasri_ghiras_prod`.`qtstkjza6_postmeta`(`post_id`, `meta_key`, `meta_value`) VALUE ({posten}, '_thumbnail_id', {imgid});\"\n",
        "                    cur.execute(query3)\n",
        "                else:\n",
        "                    print(\"No cover id\")\n",
        "            else:\n",
        "                print(\"No post id\")  \n",
        "##\n",
        "\n",
        "# Create thumbnails from URLs\n",
        "\n",
        "post_date = post_date_gmt = img_url = title = img_id = 0\n",
        "\"INSERT INTO qtstkjza6_posts (post_author, post_date, post_date_gmt, post_status, post_modified, post_modified_gmt, guid, post_type, post_mime_type) VALUES ( 77777,  '{post_date}' ,  '{post_date_gmt}' , 'inherit',  '{post_date}' ,  '{post_date_gmt}' ,  '{img_url}' , 'attachment', 'image/jpeg') ;\"\n",
        "last_id  = \"SELECT LAST_INSERT_ID(); \"\n",
        "img_id = cur.execute(last_id)\n",
        "\"INSERT INTO `emasri_ghiras_prod`.`qtstkjza6_postmeta` (`post_id`, `meta_key`, `meta_value`) VALUES (  '{img_id}' , '_wp_attached_file', '{img_url}'); \"\n",
        "\"INSERT INTO `emasri_ghiras_prod`.`qtstkjza6_postmeta` ( `post_id`, `meta_key`, `meta_value`) VALUES (  '{img_id}' , '_wp_attachment_image_alt', ''); \"\n",
        "\"INSERT INTO `emasri_ghiras_prod`.`qtstkjza6_postmeta` ( `post_id`, `meta_key`, `meta_value`) VALUES (  '{img_id}' , '_wp_attachment_metadata', 'a:2:{s:5:\\\"width\\\";s:4:\\\"1620\\\";s:6:\\\"height\\\";s:4:\\\"1080\\\";}'); \"\n",
        "\n",
        "def mysql_thumbnails(conn: MySQLdb.Connection):\n",
        "    print(f\"Auto commit: {conn.get_autocommit()}\")\n",
        "    conn.set_character_set('utf8')\n",
        "    cur: MySQLdb.cursors.Cursor = conn.cursor()\n",
        "\n",
        "    for obj in json_obj['posts']:\n",
        "        mysql_ensure(conn)\n",
        "\n",
        "        post_date = obj['date']\n",
        "        post_date_gmt = obj['dategmt']\n",
        "        img_url = obj['image']\n",
        "        title = obj['title']\n",
        "\n",
        "        insert = f\"INSERT INTO qtstkjza6_posts (post_author, post_date, post_date_gmt, post_status, post_modified, post_modified_gmt, guid, post_type, post_mime_type) VALUES ( 77777,  '{post_date}' ,  '{post_date_gmt}' , 'inherit',  '{post_date}' ,  '{post_date_gmt}' ,  '{img_url}' , 'attachment', 'image/jpeg') ;\"\n",
        "        cur.execute(insert)\n",
        "\n",
        "        last_id  = \"SELECT LAST_INSERT_ID(); \"\n",
        "        cur.execute(last_id)\n",
        "        img_id = cur.fetchone()[0]\n",
        "        obj['img_id'] = img_id\n",
        "\n",
        "        insert = f\"INSERT INTO `emasri_ghiras_prod`.`qtstkjza6_postmeta` (`post_id`, `meta_key`, `meta_value`) VALUES (  '{img_id}' , '_wp_attached_file', '{img_url}'); \"\n",
        "        cur.execute(insert)\n",
        "        insert = f\"INSERT INTO `emasri_ghiras_prod`.`qtstkjza6_postmeta` ( `post_id`, `meta_key`, `meta_value`) VALUES (  '{img_id}' , '_wp_attachment_image_alt', '{title}'); \"\n",
        "        cur.execute(insert)\n",
        "        insert = f\"INSERT INTO `emasri_ghiras_prod`.`qtstkjza6_postmeta` ( `post_id`, `meta_key`, `meta_value`) VALUES (  '{img_id}' , '_wp_attachment_metadata', 'a:2:{{s:5:\\\"width\\\";s:4:\\\"1620\\\";s:6:\\\"height\\\";s:4:\\\"1080\\\";}}'); \"\n",
        "        cur.execute(insert)\n",
        "##\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VbNn1EcIrgeB"
      },
      "source": [
        "#### Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vYgy_QNALj3Y"
      },
      "outputs": [],
      "source": [
        "#@title  { form-width: \"2%\" }\n",
        "#@markdown\n",
        "\n",
        "import sys\n",
        "from IPython import display\n",
        "\n",
        "MakeTimeStamp= 1\n",
        "SpeedTest = 2\n",
        "PrintJSReconnect = 3\n",
        "\n",
        "Operation = SpeedTest #@param [\"SpeedTest\", \"MakeTimeStamp\", \"PrintJSReconnect\"] {type: \"raw\"}\n",
        "\n",
        "ytimage = \"https://img.youtube.com/vi/E429yLC6Riw/maxresdefault.jpg\"\n",
        "ytthumb = \"https://img.youtube.com/vi/9SpTvpalmwc/hqdefault.jpg\"\n",
        "\n",
        "def getts():\n",
        "    from datetime import datetime\n",
        "    ts = datetime.now().timestamp()\n",
        "    print(ts)\n",
        "\n",
        "def speedtest():\n",
        "    if not \"speedtest\" in sys.modules:\n",
        "        !curl -s https://packagecloud.io/install/repositories/ookla/speedtest-cli/script.deb.sh | sudo bash &> /dev/null\n",
        "        !sudo apt-get install speedtest &> /dev/null\n",
        "    !speedtest\n",
        "\n",
        "def printjsreconnect():\n",
        "    js = \"function ClickConnect() { console.info('Checking connection.'); btn = document.getElementById('ok'); if (btn != null) { console.info('Client is disconnected.'); console.log('Reconnecting.'); btn.click() } else{console.info('Client is connected.');} } setInterval(ClickConnect, 5000)\"\n",
        "    display(display.Javascript(js))\n",
        "    print(js)\n",
        "\n",
        "if Operation == MakeTimeStamp:\n",
        "    getts()\n",
        "\n",
        "elif Operation == SpeedTest:\n",
        "    speedtest()\n",
        "\n",
        "elif Operation == PrintJSReconnect:\n",
        "    printjsreconnect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wDQTm6xzfUA8"
      },
      "outputs": [],
      "source": [
        "#@title  { form-width: \"50px\" }\n",
        "#@markdown #### codex\n",
        "\n",
        "\n",
        "import ftputil\n",
        "\n",
        "# Download some files from the login directory.\n",
        "with ftputil.FTPHost(\"ftp.domain.com\", \"user\", \"password\") as ftphost:\n",
        "    names = ftphost.listdir(ftphost.curdir)\n",
        "    for name in names:\n",
        "        if ftphost.path.isfile(name):\n",
        "            ftphost.download(name, name)  # remote, local\n",
        "    \n",
        "    # Make a new directory and copy a remote file into it.\n",
        "    ftphost.mkdir(\"newdir\")\n",
        "    with ftphost.open(\"index.html\", \"rb\") as source:\n",
        "        with ftphost.open(\"newdir/index.html\", \"wb\") as target:\n",
        "            ftphost.copyfileobj(source, target)  # similar to shutil.copyfileobj\n",
        "    \n",
        "    ftphost.upload(source, target, callback=None)\n",
        "    ftphost.upload_if_newer(source, target, callback=None)\n",
        "\n",
        "####\n",
        "# ftp dir size\n",
        "\n",
        "s0 = 0\n",
        "if ftp.path.isfile(p0):\n",
        "    s0 = ftp.path.getsize(p0)\n",
        "else:  \n",
        "    for path, dirs, files in ftp.walk(p0):\n",
        "        for f in files:\n",
        "            fp = path + '/' + f\n",
        "            s0 += ftp.path.getsize(fp)\n",
        "item = \"{:>6}  {}\".format(data_str(s0), name)\n",
        "total_size += s0\n",
        "\n",
        "####\n",
        "# writing js\n",
        "\n",
        "def write_json( dct, filename = 'scrape_output.json'):\n",
        "    if not dct:\n",
        "        error(\"Empty input\")\n",
        "        raise Exception(\"Empty input\") \n",
        "  \n",
        "    text = json.dumps(dct, ensure_ascii = False, indent = 2)\n",
        "    output_file = filename\n",
        "    i = 0\n",
        "    while True:\n",
        "        i += 1\n",
        "        if os.path.exists(output_file):\n",
        "            sch = re.search(extdot_re, output_file)\n",
        "            if sch:\n",
        "                output_file = re.sub(extdot_re, f\"{i}.\", filename)\n",
        "            else:\n",
        "                output_file = f\"{filename}{i}\"  \n",
        "        else: \n",
        "            break\n",
        "\n",
        "    with open(output_file, 'w', encoding = 'utf8') as file:\n",
        "        file.write(text)\n",
        "####\n",
        "# xml view\n",
        "\n",
        "def xmlview(file, element, attr = \"\"):\n",
        "    items = xmlcall(file, element)\n",
        "    print(f\"All items: {len(items)}\\n\")\n",
        "    for i in range(len(items)):\n",
        "        val = items[i].text if not attr else items[i].get(attr)\n",
        "        print(f\"Item {i:<5}->   {val:<10}\")\n",
        "    return items\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aFioL1kb5h0n"
      },
      "outputs": [],
      "source": [
        "#@title  { form-width: \"50px\" }\n",
        "#@markdown\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "WebTools",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "440a3056a1bc9993a03d768f3bb611285f12fca14d7742b06073b1a4a5830584"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
